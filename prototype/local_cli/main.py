import os
import sys
import json
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from PIL import Image, ImageDraw, ImageFont
import requests
from requests.auth import HTTPBasicAuth
try:
    import google.generativeai as genai  # type: ignore
    from google.generativeai import types
except Exception:
    genai = None  # type: ignore
from textwrap import dedent


def maybe_load_dotenv() -> None:
    try:
        from dotenv import load_dotenv  # type: ignore
    except Exception:
        return
    script_dir = Path(__file__).resolve().parent
    # Prefer prototype/local_cli/.env, then queries/.env, then CWD, then repo root
    candidates = [
        script_dir / ".env",                          # .../prototype/local_cli/.env
        (script_dir / "queries" / ".env"),           # .../prototype/local_cli/queries/.env
        Path.cwd() / ".env",                          # current working dir
        Path(__file__).resolve().parents[2] / ".env",  # repo root (best-effort)
    ]
    for p in candidates:
        try:
            if p.exists():
                load_dotenv(p, override=False)
                if os.getenv("DASHBOARD_LOG", "1").lower() in ("1", "true", "yes"):
                    print(f"[env] loaded: {p}")
        except Exception:
            pass


def _sanitize_api_key(raw: Optional[str]) -> Optional[str]:
    if not raw:
        return raw
    s = str(raw).strip().strip('"').strip("'")
    # Prefer substring starting at 'AIza' if present
    start = s.find('AIza')
    if start >= 0:
        s = s[start:]
    # Allowed chars for Google API keys (alnum, '-', '_')
    allowed = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_')
    out = []
    for ch in s:
        if ch in allowed:
            out.append(ch)
        else:
            # stop at first invalid char to drop trailing comments like '#API'
            break
    filtered = ''.join(out)
    return filtered or None


def get_json_from_script(script_path: str, env_extra: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
    env = os.environ.copy()
    if env_extra:
        env.update(env_extra)
    env["OUTPUT_JSON"] = "1"
    env["PYTHONUTF8"] = "1"
    base_dir = Path(__file__).resolve().parent
    proc = __import__("subprocess").run(
        [sys.executable, "-X", "utf8", script_path],
        capture_output=True,
        text=True,
        encoding="utf-8",
        env=env,
        cwd=str(base_dir),
    )
    if proc.returncode != 0:
        print(proc.stdout)
        print(proc.stderr, file=sys.stderr)
        raise RuntimeError("„Éá„Éº„ÇøÂèñÂæó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
    line = proc.stdout.strip().splitlines()[-1]
    return json.loads(line)


def get_json_from_script_args(script_path: str, args: List[str], env_extra: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
    env = os.environ.copy()
    if env_extra:
        env.update(env_extra)
    env["OUTPUT_JSON"] = "1"
    env["PYTHONUTF8"] = "1"
    base_dir = Path(__file__).resolve().parent
    proc = __import__("subprocess").run(
        [sys.executable, "-X", "utf8", script_path, *args],
        capture_output=True,
        text=True,
        encoding="utf-8",
        env=env,
        cwd=str(base_dir),
    )
    if proc.returncode != 0:
        print(proc.stdout)
        print(proc.stderr, file=sys.stderr)
        raise RuntimeError(f"„Éá„Éº„ÇøÂèñÂæó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {script_path} {' '.join(args)}")
    line = proc.stdout.strip().splitlines()[-1]
    return json.loads(line)


def api_get(url: str, auth: HTTPBasicAuth, params: Optional[Dict[str, Any]] = None) -> Tuple[int, Optional[Dict[str, Any]], str]:
    try:
        resp = requests.get(
            url,
            auth=auth,
            headers={"Accept": "application/json"},
            params=params,
            timeout=30,
        )
    except requests.RequestException as e:
        return 0, None, f"HTTP„É™„ÇØ„Ç®„Çπ„Éà„Ç®„É©„Éº: {e}"

    if resp.status_code == 200:
        try:
            return 200, resp.json(), ""
        except json.JSONDecodeError:
            return 200, None, "„É¨„Çπ„Éù„É≥„Çπ„ÅÆJSONËß£Êûê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü"
    else:
        return resp.status_code, None, resp.text


def search_issue_keys(JIRA_DOMAIN: str, auth: HTTPBasicAuth, jql: str, limit: int = 10) -> List[str]:
    try:
        url = f"{JIRA_DOMAIN}/rest/api/3/search"
        params = {"jql": jql, "fields": "key", "maxResults": limit}
        code, data, _ = api_get(url, auth, params=params)
        if code == 200 and data:
            return [str(it.get("key")) for it in (data.get("issues") or [])]
    except Exception:
        pass
    return []


def resolve_board(JIRA_DOMAIN: str, auth: HTTPBasicAuth) -> Tuple[int, Optional[Dict[str, Any]], str]:
    board_id = os.getenv("JIRA_BOARD_ID")
    project_key = os.getenv("JIRA_PROJECT_KEY")

    if board_id and board_id.isdigit():
        return api_get(f"{JIRA_DOMAIN}/rest/agile/1.0/board/{board_id}", auth)

    if board_id and not board_id.isdigit():
        params: Dict[str, Any] = {"maxResults": 50}
        if project_key:
            params["projectKeyOrId"] = project_key
        code, data, err = api_get(f"{JIRA_DOMAIN}/rest/agile/1.0/board", auth, params=params)
        if code != 200 or not data:
            return code, None, f"„Éú„Éº„Éâ‰∏ÄË¶ßÂèñÂæó„Å´Â§±Êïó: {err}"
        items = data.get("values", [])
        exact = [x for x in items if str(x.get("name", "")).lower() == board_id.lower()]
        if exact:
            return 200, exact[0], ""
        partial = [x for x in items if board_id.lower() in str(x.get("name", "")).lower()]
        if partial:
            return 200, partial[0], ""
        code2, data2, err2 = api_get(f"{JIRA_DOMAIN}/rest/agile/1.0/board", auth, params={"maxResults": 50})
        if code2 == 200 and data2:
            items2 = data2.get("values", [])
            exact = [x for x in items2 if str(x.get("name", "")).lower() == board_id.lower()]
            if exact:
                return 200, exact[0], ""
            partial = [x for x in items2 if board_id.lower() in str(x.get("name", "")).lower()]
            if partial:
                return 200, partial[0], ""
        return 404, None, f"„Éú„Éº„ÉâÂêç '{board_id}' „ÅØË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü"

    params: Dict[str, Any] = {"maxResults": 50}
    if project_key:
        params["projectKeyOrId"] = project_key
    code, data, err = api_get(f"{JIRA_DOMAIN}/rest/agile/1.0/board", auth, params=params)
    if code == 200 and data and data.get("values"):
        return 200, data.get("values")[0], ""
    if code != 200:
        return code, None, f"„Éú„Éº„Éâ‰∏ÄË¶ßÂèñÂæó„Å´Â§±Êïó: {err}"
    code2, data2, err2 = api_get(f"{JIRA_DOMAIN}/rest/agile/1.0/board", auth, params={"maxResults": 50})
    if code2 == 200 and data2 and data2.get("values"):
        return 200, data2.get("values")[0], ""
    return 404, None, "„Éú„Éº„Éâ„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü"


def try_infer_project_key_from_board(JIRA_DOMAIN: str, auth: HTTPBasicAuth, board: Dict[str, Any]) -> Optional[str]:
    loc = (board or {}).get("location") or {}
    pkey = loc.get("projectKey")
    if pkey:
        return str(pkey)
    bid = board.get("id")
    try:
        bid_int = int(bid)
    except Exception:
        return None
    code, detail, _ = api_get(f"{JIRA_DOMAIN}/rest/agile/1.0/board/{bid_int}", auth)
    if code == 200 and detail:
        loc = (detail or {}).get("location") or {}
        pkey = loc.get("projectKey")
        if pkey:
            return str(pkey)
    return None


def count_boards_for_project(JIRA_DOMAIN: str, auth: HTTPBasicAuth, project_key: Optional[str]) -> int:
    params: Dict[str, Any] = {"maxResults": 50}
    if project_key:
        params["projectKeyOrId"] = project_key
    code, data, _ = api_get(f"{JIRA_DOMAIN}/rest/agile/1.0/board", auth, params=params)
    if code == 200 and data:
        return int(len(data.get("values", []) or []))
    return 1


def count_active_sprints_for_board(JIRA_DOMAIN: str, auth: HTTPBasicAuth, board_id: int) -> int:
    code, data, _ = api_get(
        f"{JIRA_DOMAIN}/rest/agile/1.0/board/{board_id}/sprint",
        auth,
        params={"state": "active", "maxResults": 50},
    )
    if code == 200 and data:
        n = int(len(data.get("values", []) or []))
        return n if n > 0 else 1
    return 1


def resolve_active_sprint(JIRA_DOMAIN: str, auth: HTTPBasicAuth, board_id: int) -> Optional[Dict[str, Any]]:
    code, data, _ = api_get(
        f"{JIRA_DOMAIN}/rest/agile/1.0/board/{board_id}/sprint",
        auth,
        params={"state": "active", "maxResults": 50},
    )
    if code == 200 and data:
        vals = data.get("values", []) or []
        if vals:
            sid = vals[0].get("id")
            scode, sdata, _ = api_get(f"{JIRA_DOMAIN}/rest/agile/1.0/sprint/{sid}", auth)
            if scode == 200 and sdata:
                return sdata
            return vals[0]
    return None


def approximate_count(JIRA_DOMAIN: str, auth: HTTPBasicAuth, jql: str) -> Tuple[int, Optional[int], str]:
    url = f"{JIRA_DOMAIN}/rest/api/3/search/approximate/count"
    code, data, err = api_get(url, auth, params={"jql": jql})
    if code == 200 and isinstance(data, dict):
        try:
            cnt = int((data.get("approximate") or {}).get("total") or 0)
            return 200, cnt, ""
        except Exception:
            pass
    return code, None, err


def search_count(JIRA_DOMAIN: str, auth: HTTPBasicAuth, jql: str) -> Tuple[int, Optional[int], str]:
    """Fallback using Search API to retrieve accurate total without fetching issues.
    Uses maxResults=0 to avoid payload; relies on 'total' field in response.
    """
    try:
        resp = requests.get(
            f"{JIRA_DOMAIN}/rest/api/3/search",
            auth=auth,
            headers={"Accept": "application/json"},
            params={"jql": jql, "startAt": 0, "maxResults": 0, "fields": "none"},
            timeout=30,
        )
    except requests.RequestException as e:
        return 0, None, f"HTTP„É™„ÇØ„Ç®„Çπ„Éà„Ç®„É©„Éº: {e}"
    if resp.status_code != 200:
        return resp.status_code, None, resp.text
    try:
        data = resp.json()
        total = int(data.get("total", 0))
        return 200, total, ""
    except Exception as e:
        return 200, None, f"JSONËß£ÊûêÂ§±Êïó: {e}"


def agile_sprint_count(JIRA_DOMAIN: str, auth: HTTPBasicAuth, sprint_id: int, jql_filter: Optional[str] = None) -> Tuple[int, Optional[int], str]:
    """Count issues in a sprint via Agile API without fetching items.
    Uses maxResults=0 for efficiency. Optional JQL filter applies on top.
    """
    params: Dict[str, Any] = {"maxResults": 0}
    if jql_filter:
        params["jql"] = jql_filter
    try:
        resp = requests.get(
            f"{JIRA_DOMAIN}/rest/agile/1.0/sprint/{int(sprint_id)}/issue",
            auth=auth,
            headers={"Accept": "application/json"},
            params=params,
            timeout=30,
        )
    except requests.RequestException as e:
        return 0, None, f"HTTP„É™„ÇØ„Ç®„Çπ„Éà„Ç®„É©„Éº: {e}"
    if resp.status_code != 200:
        return resp.status_code, None, resp.text
    try:
        data = resp.json()
        total = int(data.get("total", 0))
        return 200, total, ""
    except Exception as e:
        return 200, None, f"JSONËß£ÊûêÂ§±Êïó: {e}"


def try_load_font(size: int) -> ImageFont.ImageFont:
    candidates: List[str] = []
    if os.name == "nt":
        candidates = [
            r"C:\\Windows\\Fonts\\meiryo.ttc",       # Meiryo (Êó•Êú¨Ë™û)
            r"C:\\Windows\\Fonts\\YuGothR.ttc",      # Yu Gothic Regular
            r"C:\\Windows\\Fonts\\YuGothM.ttc",      # Yu Gothic Medium
            r"C:\\Windows\\Fonts\\msgothic.ttc",     # MS Gothic
            r"C:\\Windows\\Fonts\\msmincho.ttc",     # MS Mincho
            r"C:\\Windows\\Fonts\\segoeui.ttf",      # Fallback (Ëã±Êï∞Â≠ó)
        ]
    else:
        candidates = [
            "/System/Library/Fonts/„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W3.ttc",
            "/Library/Fonts/„Éí„É©„ÇÆ„ÉéËßí„Ç¥ ProN W3.otf",
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/noto-cjk/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/noto/NotoSansJP-Regular.otf",
        ]
    # Generic fallbacks
    candidates += ["NotoSansCJKjp-Regular.otf", "NotoSansCJKJP-Regular.otf", "NotoSansJP-Regular.otf", "DejaVuSans.ttf", "arial.ttf"]

    for path in candidates:
        try:
            return ImageFont.truetype(path, size)
        except Exception:
            continue
    return ImageFont.load_default()


def fmt_date(dt_str: Optional[str]) -> Optional[str]:
    if not dt_str:
        return None
    try:
        from datetime import datetime
        for fmt in ("%Y-%m-%d", "%Y-%m-%dT%H:%M:%S.%f%z", "%Y-%m-%dT%H:%M:%S%z", "%Y-%m-%dT%H:%M:%S"):
            try:
                d = datetime.strptime(dt_str, fmt)
                return d.strftime("%Y/%m/%d")
            except Exception:
                continue
    except Exception:
        pass
    return dt_str.replace("-", "/")


def maybe_gemini_summary(api_key: Optional[str], context: Dict[str, Any]) -> Optional[str]:
    # Allow forced disable to avoid network calls
    if os.getenv("GEMINI_DISABLE", "").lower() in ("1", "true", "yes"):
        return None
    if not api_key:
        return None
    if not genai:
        if os.getenv("GEMINI_DEBUG", "").lower() in ("1", "true", "yes"):
            print("[Gemini] google-generativeai not installed or failed to import")
        return None
    try:
        # Configuration
        model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite")
        fallback_model = os.getenv("GEMINI_MODEL_FALLBACK", "gemini-1.5-flash")
        try:
            timeout_s = float(os.getenv("GEMINI_TIMEOUT", "25"))
        except Exception:
            timeout_s = 25.0
        try:
            retries = int(os.getenv("GEMINI_RETRIES", "2"))
        except Exception:
            retries = 2
        temp = float(os.getenv("GEMINI_TEMPERATURE", "0.1"))
        top_p = float(os.getenv("GEMINI_TOP_P", "0.9"))

        # Use REST transport to avoid gRPC plugin metadata issues
        genai.configure(api_key=api_key, transport="rest")
        generation_config = {"temperature": temp, "top_p": top_p, "max_output_tokens": 640}
        def _call(model_id: str) -> Optional[str]:
            m = genai.GenerativeModel(model_id, generation_config=generation_config)
            last_err: Optional[Exception] = None
            for attempt in range(retries + 1):
                try:
                    out = m.generate_content(prompt, request_options={"timeout": timeout_s})
                    text = (getattr(out, "text", None) or "").strip()
                    if not text:
                        # try concatenating from candidates
                        cand_texts = []
                        for c in getattr(out, "candidates", []) or []:
                            parts = getattr(getattr(c, "content", None), "parts", []) or []
                            frag = "".join(getattr(p, "text", "") for p in parts)
                            if frag:
                                cand_texts.append(frag)
                        text = "\n".join(t for t in cand_texts if t).strip()
                    if text:
                        return text
                except Exception as e:
                    last_err = e
                # backoff
                try:
                    import time as _t
                    _t.sleep(0.6 * (attempt + 1))
                except Exception:
                    pass
            # if all attempts failed
            if os.getenv("GEMINI_DEBUG", "").lower() in ("1", "true", "yes") and last_err:
                print(f"[Gemini] error on model {model_id}: {last_err}")
            return None
        # --- „Éó„É≠„É≥„Éó„ÉàÔºàÂá∫ÂäõÂΩ¢Âºè„ÇíÊï¥ÂΩ¢Ôºâ ---
        intro = dedent(
            """
            „ÅÇ„Å™„Åü„ÅØÁµåÈ®ìË±äÂØå„Å™„Ç¢„Ç∏„É£„Ç§„É´„Ç≥„Éº„ÉÅÂÖº„Éá„Éº„Çø„Ç¢„Éä„É™„Çπ„Éà„Åß„Åô„ÄÇÊèêÁ§∫„Åô„Çã„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà(JSON)„ÅÆ„Åø„ÇíÂîØ‰∏Ä„ÅÆ‰∫ãÂÆüÊÉÖÂ†±Ê∫ê„Å®„Åó„Å¶ÂàÜÊûê„Åó„ÄÅ
            ‰ªÆÂÆö„ÇÑÊÉ≥ÂÉè„ÅÆÊï∞ÂÄ§„ÅØÁî®„ÅÑ„Åö„ÄÅ[Âá∫ÂäõÂΩ¢Âºè]„Å´Âé≥ÂØÜ„Å´Âæì„Å£„Å¶„ÄÅÂÆüÂãô„Å´Áõ¥Áµê„Åô„ÇãÊ¥ûÂØü„Å®„Ç¢„ÇØ„Ç∑„Éß„É≥„ÇíÊèêÁ§∫„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
            """
        )
        
        output_format = dedent(
            """
            ## üéØ ÁµêË´ñÔºà1Ë°åÊñ≠Ë®ÄÔºâ
            ÂÆå‰∫ÜÁéá[X%] - [È†ÜË™ø‚úÖ/Ê≥®ÊÑè‚ö†Ô∏è/Âç±Èô∫üö®] ÊÆã[Y]Êó•„ÅßÁõÆÊ®ô[Z%]Ôºà[ÁêÜÁî±5Â≠ó‰ª•ÂÜÖ]Ôºâ

            ## üö® Âç≥ÂÆüË°å„Ç¢„ÇØ„Ç∑„Éß„É≥ÔºàÈáçË¶ÅÈ†Ü3„Å§Ôºâ
            1. [ÊãÖÂΩìËÄÖ] ‚Üí [„Çø„Çπ„ÇØ] Ôºà[ÊúüÈôê]Ôºâ
            2. [ÊãÖÂΩìËÄÖ] ‚Üí [„Çø„Çπ„ÇØ] Ôºà[ÊúüÈôê]Ôºâ 
            3. [ÊãÖÂΩìËÄÖ] ‚Üí [„Çø„Çπ„ÇØ] Ôºà[ÊúüÈôê]Ôºâ

            ## üìä Ê†πÊã†Ôºà2Ë°å‰ª•ÂÜÖÔºâ
            ‚Ä¢ „Éá„Éº„Çø: ÂÆå‰∫Ü[X]/ÂÖ®[Y]‰ª∂„ÄÅÂøÖË¶ÅÊ∂àÂåñ[Z]‰ª∂/Êó•ÔºàÂÆüÁ∏æ[W]‰ª∂/Êó•Ôºâ
            ‚Ä¢ ÂïèÈ°å: [ÊúÄÂ§ß„É™„Çπ„ÇØ] + [„Éú„Éà„É´„Éç„ÉÉ„ÇØ] = [ÂΩ±ÈüøÂ∫¶Êï∞ÂÄ§]
            """
        )
        
        constraints = dedent(
            """
            „ÄêÂé≥ÂÆàÂà∂Á¥Ñ„Äë
            - ÊõñÊòßË™ûÁ¶ÅÊ≠¢ÔºàÊé®Ê∏¨„ÉªÂèØËÉΩÊÄß„Éª„Åä„Åù„Çâ„ÅèÁ≠âÔºâ
            - Â∞ÇÈñÄË™û‚ÜíÂπ≥ÊòìË™ûÔºàÂÆüË£Ö‚Üí‰ΩúÊàê„ÄÅ„É¨„Éì„É•„Éº‚ÜíÁ¢∫Ë™ç„ÄÅ„Ç¢„Çµ„Ç§„É≥‚ÜíÂâ≤ÂΩìÔºâ
            - ÂÖ®Êï∞ÂÄ§ÂøÖÈ†à„ÄÅÊãÖÂΩìËÄÖÂêç„ÉªÊúüÈôêÂøÖÈ†à
            - ÂêÑ„Çª„ÇØ„Ç∑„Éß„É≥Ë¶èÂÆöË°åÊï∞Âé≥ÂÆàÔºàÁµêË´ñ1Ë°å„ÄÅ„Ç¢„ÇØ„Ç∑„Éß„É≥3Ë°å„ÄÅÊ†πÊã†2Ë°åÔºâ
            - ÊñáÂ≠óÊï∞300Â≠ó‰ª•ÂÜÖ„ÄÅMarkdownÂΩ¢Âºè
            - JSON„Éá„Éº„Çø‰ª•Â§ñ„ÅÆÊÉÖÂ†±‰ΩøÁî®Á¶ÅÊ≠¢
            """
        )
        
        format_specs = dedent(
            """
            „ÄêÂá∫Âäõ‰ªïÊßò„Äë
            ‚Ä¢ „Çπ„ÉÜ„Éº„Çø„ÇπÂà§ÂÆö: ÂÆå‰∫ÜÁéá80%‰ª•‰∏ä‚Üí‚úÖÈ†ÜË™ø„ÄÅ60-79%‚Üí‚ö†Ô∏èÊ≥®ÊÑè„ÄÅ60%Êú™Ê∫Ä‚Üíüö®Âç±Èô∫
            ‚Ä¢ „Ç¢„ÇØ„Ç∑„Éß„É≥ÂÑ™ÂÖàÈ†Ü‰Ωç: 1)ÊúüÈôêË∂ÖÈÅé 2)ÊúüÈôêÈñìËøë 3)È´òÂÑ™ÂÖàÂ∫¶Êú™ÁùÄÊâã 4)Á¢∫Ë™çÂæÖ„Å° 5)Êú™Ââ≤ÂΩì
            ‚Ä¢ Êï∞ÂÄ§ÂøÖÈ†àÈ†ÖÁõÆ: ÂÆå‰∫ÜÁéá%„ÄÅÊÆãÊó•Êï∞„ÄÅÂÆå‰∫Ü‰ª∂Êï∞/ÂÖ®‰ª∂Êï∞„ÄÅÂøÖË¶ÅÊ∂àÂåñ‰ª∂Êï∞/Êó•„ÄÅÂÆüÁ∏æ‰ª∂Êï∞/Êó•
            ‚Ä¢ ÊãÖÂΩìËÄÖË°®Ë®ò: „Éï„É´„Éç„Éº„É†‰∏çË¶Å„ÄÅÂßì„ÅÆ„ÅøÂèØÔºàÁî∞‰∏≠„ÄÅ‰ΩêËó§Á≠âÔºâ
            ‚Ä¢ ÊúüÈôêË°®Ë®ò: Áõ∏ÂØæË°®ÁèæÔºà‰ªäÊó•„ÄÅÊòéÊó•„ÄÅXÊó•ÂæåÔºâ„Åæ„Åü„ÅØÂÖ∑‰ΩìÊó•ÊôÇ
            """
        )
        
        example_output = dedent(
            """
            „ÄêÂá∫Âäõ‰æã„Äë
            ## üéØ ÁµêË´ñÔºà1Ë°åÊñ≠Ë®ÄÔºâ
            ÂÆå‰∫ÜÁéá65% - Ê≥®ÊÑè‚ö†Ô∏è ÊÆã3Êó•„ÅßÁõÆÊ®ô80%ÔºàÈÅÖÂª∂ÊúâÔºâ

            ## üö® Âç≥ÂÆüË°å„Ç¢„ÇØ„Ç∑„Éß„É≥ÔºàÈáçË¶ÅÈ†Ü3„Å§Ôºâ
            1. Áî∞‰∏≠ ‚Üí API‰ΩúÊàêÂÆå‰∫Ü ÔºàÊòéÊó•17ÊôÇÔºâ
            2. ‰ΩêËó§ ‚Üí UIÁ¢∫Ë™çÂÆå‰∫Ü ÔºàÊòéÊó•12ÊôÇÔºâ
            3. Â±±Áî∞ ‚Üí DBË®≠Ë®àÂâ≤ÂΩì Ôºà‰ªäÊó•‰∏≠Ôºâ

            ## üìä Ê†πÊã†Ôºà2Ë°å‰ª•ÂÜÖÔºâ
            ‚Ä¢ „Éá„Éº„Çø: ÂÆå‰∫Ü13/20‰ª∂„ÄÅÂøÖË¶ÅÊ∂àÂåñ3‰ª∂/Êó•ÔºàÂÆüÁ∏æ2.1‰ª∂/Êó•Ôºâ
            ‚Ä¢ ÂïèÈ°å: APIÈÅÖÂª∂2Êó• + Á¢∫Ë™çÂæÖ„Å°5‰ª∂ = ÁõÆÊ®ôÊú™ÈÅî„É™„Çπ„ÇØ40%
            """
        )
        
        # „Éó„É≠„É≥„Éó„ÉàÁµÑ„ÅøÁ´ã„Å¶
        prompt = (
            intro
            + "\n[Âá∫ÂäõÂΩ¢Âºè]\n"
            + output_format
            + "\n" + constraints
            + "\n" + format_specs
            + "\n" + example_output
            + f"\n\n„ÄêÂàÜÊûêÂØæË±°„Éá„Éº„Çø„Äë\n„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà(JSON): {json.dumps(context, ensure_ascii=False, indent=2)}\n"
            + "\n‰∏äË®òJSON„Éá„Éº„Çø„ÅÆ„Åø„ÇíÊ†πÊã†„Å®„Åó„Å¶„ÄÅÂá∫ÂäõÂΩ¢Âºè„Å´Âé≥ÂØÜ„Å´Âæì„ÅÑÂàÜÊûêÁµêÊûú„ÇíÂá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        )
        # Try primary then fallback model
        text = _call(model_name)
        if not text and fallback_model and fallback_model != model_name:
            text = _call(fallback_model)
        if not text and os.getenv("GEMINI_DEBUG", "").lower() in ("1", "true", "yes"):
            print("[Gemini] empty response from both primary and fallback models")
        return text
    except Exception as e:
        if os.getenv("GEMINI_DEBUG", "").lower() in ("1", "true", "yes"):
            print(f"[Gemini] error: {e}")
        return None


def maybe_gemini_justify_evidences(
    api_key: Optional[str], evidences: List[Dict[str, Any]]
) -> Dict[str, str]:
    """
    ÂêÑ„Ç®„Éì„Éá„É≥„Çπ„ÅÆ„ÄåÈáçË¶Å„Å™ÁêÜÁî±„Äç„ÇíGemini„Åß1ÊñáÁîüÊàê„Åó„ÄÅ{key: reason} „ÇíËøî„Åô„ÄÇ
    - Áí∞Â¢ÉÂ§âÊï∞ GEMINI_EVIDENCE_REASON=0 „ÅßÁÑ°ÂäπÂåñÔºàÊó¢ÂÆö: ÊúâÂäπÔºâ
    - Â§±ÊïóÊôÇ„ÅØÁ©∫dict„ÇíËøî„Åó„ÄÅÂëº„Å≥Âá∫„ÅóÂÖÉ„ÅßÂÖÉ„ÅÆÁêÜÁî±„ÇíÁ∂≠ÊåÅ
    - Èï∑„Åï‰∏äÈôê: EVIDENCE_REASON_MAX_CHARSÔºàÊó¢ÂÆö 38 ÊñáÂ≠ó„ÄÅË∂ÖÈÅéÊôÇ„ÅØÁúÅÁï•Ôºâ
    """
    try:
        if os.getenv("GEMINI_EVIDENCE_REASON", "1").lower() in ("0", "false", "no"):
            return {}
        if os.getenv("GEMINI_DISABLE", "").lower() in ("1", "true", "yes"):
            return {}
        if not api_key or not genai:
            return {}

        model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite")
        fallback_model = os.getenv("GEMINI_MODEL_FALLBACK", "gemini-1.5-flash-8b")
        try:
            timeout_s = float(os.getenv("GEMINI_TIMEOUT", "25"))
        except Exception:
            timeout_s = 25.0
        temp = float(os.getenv("GEMINI_TEMPERATURE", "0.2"))
        top_p = float(os.getenv("GEMINI_TOP_P", "0.9"))
        try:
            max_chars = int(os.getenv("EVIDENCE_REASON_MAX_CHARS", "38"))
        except Exception:
            max_chars = 38

        # ÁîüÊàê„Å´ÂøÖË¶Å„Å™ÊúÄÂ∞èÊÉÖÂ†±„ÇíÊßãÁØâ
        items = []
        for e in evidences:
            items.append({
                "key": e.get("key"),
                "summary": e.get("summary"),
                "status": e.get("status"),
                "assignee": e.get("assignee"),
                "priority": e.get("priority"),
                "duedate": e.get("duedate") or e.get("due"),
                "days": e.get("days"),
            })

        prompt = dedent(
            f"""
            „ÅÇ„Å™„Åü„ÅØ„Çπ„ÇØ„É©„É†„ÉÅ„Éº„É†„ÅÆ„Ç¢„Ç∏„É£„Ç§„É´„Ç≥„Éº„ÉÅ„Åß„Åô„ÄÇ‰ª•‰∏ã„ÅÆÂêÑÂ∞è„Çø„Çπ„ÇØ„Å´„Å§„ÅÑ„Å¶„ÄÅ„Å™„ÅúÈáçË¶Å„Åã„ÇíÊó•Êú¨Ë™û„Åß1Êñá„Åö„Å§‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
            Âà∂Á¥Ñ:
            - ÂêÑË°å„ÅØÊúÄÂ§ß{max_chars}ÊñáÂ≠ó‰ª•ÂÜÖ„ÅßÁ∞°ÊΩî„Å´„ÄÇ
            - Ê†πÊã†„ÅØÊªûÁïôÊó•Êï∞/ÊúüÈôê/ÂÑ™ÂÖàÂ∫¶/Áä∂ÊÖã/ÊãÖÂΩì„Å™„Å©ÂÖ•Âäõ„Åã„ÇâÂ∞é„Åë„Çã‰∫ãÂÆü„ÅÆ„Åø„ÄÇ
            - Êñ≠Ë®ÄÁöÑ„ÅßÂÆüÂãôÁöÑ„Å™Ë°®ÁèæÔºà‰æã: ÊúüÈôêÂ∑Æ„ÅóËø´„Çä„ÄÅÂÑ™ÂÖàÂ∫¶È´ò„ÄÅ„É¨„Éì„É•„ÉºÊªûÁïô Á≠âÔºâ„ÄÇ
            Âá∫ÂäõÂΩ¢Âºè„ÅØJSON„ÅÆ„Åø„Åß„ÄÅ„Ç≠„Éº„ÇíË™≤È°å„Ç≠„Éº„ÄÅÂÄ§„ÇíÁêÜÁî±ÊñáÂ≠óÂàó„Å®„Åó„Åü„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÅßËøî„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

            ÂÖ•Âäõ: {json.dumps(items, ensure_ascii=False)}
            Âá∫Âäõ: {{ "KEY": "ÁêÜÁî±" }} „ÅÆ„Éû„ÉÉ„Éó„ÅÆ„Åø„ÇíËøî„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
            """
        ).strip()

        genai.configure(api_key=api_key, transport="rest")
        generation_config = {"temperature": temp, "top_p": top_p, "max_output_tokens": 256}

        def _call(model_id: str) -> Optional[str]:
            try:
                m = genai.GenerativeModel(model_id, generation_config=generation_config)
                out = m.generate_content(prompt, request_options={"timeout": timeout_s})
                text = (getattr(out, "text", None) or "").strip()
                if not text:
                    # candidates fallback
                    cand_texts = []
                    for c in getattr(out, "candidates", []) or []:
                        parts = getattr(getattr(c, "content", None), "parts", []) or []
                        frag = "".join(getattr(p, "text", "") for p in parts)
                        if frag:
                            cand_texts.append(frag)
                    text = "\n".join(t for t in cand_texts if t).strip()
                return text or None
            except Exception:
                return None

        text = _call(model_name) or (fallback_model and _call(fallback_model)) or None
        if not text:
            if os.getenv("GEMINI_DEBUG", "").lower() in ("1", "true", "yes"):
                print("- AIË¶ÅÁ¥Ñ: evidence reasons Á©∫ÂøúÁ≠îÔºàÂÖÉ„ÅÆÁêÜÁî±„Çí‰ΩøÁî®Ôºâ")
            return {}

        # JSONÊäΩÂá∫
        result: Dict[str, str] = {}
        try:
            parsed = json.loads(text)
            if isinstance(parsed, dict):
                result = {str(k): str(v) for k, v in parsed.items()}
        except Exception:
            try:
                import re as _re
                m = _re.search(r"\{[\s\S]*\}", text)
                if m:
                    parsed = json.loads(m.group(0))
                    if isinstance(parsed, dict):
                        result = {str(k): str(v) for k, v in parsed.items()}
            except Exception:
                result = {}

        # ÊñáÂ≠óÊï∞Âà∂Èôê„ÇíÈÅ©Áî®
        clipped: Dict[str, str] = {}
        for e in evidences:
            k = e.get("key")
            if not k:
                continue
            v = (result.get(k) or "").strip()
            if v:
                if len(v) > max_chars:
                    # keep room for ellipsis if needed
                    clipped[k] = (v[: max(1, max_chars - 1)] + "‚Ä¶")
                else:
                    clipped[k] = v

        if os.getenv("GEMINI_DEBUG", "").lower() in ("1", "true", "yes") and clipped:
            print(f"- AIË¶ÅÁ¥Ñ: evidence reasons {len(clipped)}‰ª∂ ÁîüÊàê")
        return clipped
    except Exception as e:
        if os.getenv("GEMINI_DEBUG", "").lower() in ("1", "true", "yes"):
            print(f"[Gemini] evidence reasons error: {e}")
        return {}

def draw_png(
    output_path: str,
    data: Dict[str, Any],
    boards_n: int,
    sprints_n: int,
    sprint_name: Optional[str],
    sprint_start: Optional[str],
    sprint_end: Optional[str],
    axis_mode: str,
    target_done_rate: float,
    extras: Optional[Dict[str, Any]] = None,
) -> None:
    W, H = 1400, 980
    bg = (255, 255, 255)
    img = Image.new("RGB", (W, H), bg)
    g = ImageDraw.Draw(img)

    # Colorblind-friendly palette
    col_bg = (255, 255, 255)
    col_project = (230, 230, 230)
    col_board_focus = (200, 200, 200)
    col_board_other = (215, 215, 215)
    col_sprint_focus = (210, 210, 210)
    col_sprint_other = (235, 235, 235)
    # Unified palette (traffic-light + neutrals)
    col_task_done = (27, 158, 119)     # green
    col_task_todo = (217, 95, 2)       # orange
    col_outline = (80, 80, 80)
    col_text = (40, 40, 40)
    col_grid = (220, 220, 220)
    col_benchmark = (50, 50, 200)
    col_ok = (32, 158, 84)
    col_warn = (230, 170, 0)
    col_danger = (204, 32, 38)

    padding = 20
    project_bar_h = 40
    board_bar_h = 28
    sprint_bar_h = 22
    gap = 8
    font_xs = try_load_font(11)
    font_sm = try_load_font(12)
    font_md = try_load_font(14)
    font_lg = try_load_font(20)
    font_xl = try_load_font(28)

    def text_wh(text: str, font: ImageFont.ImageFont) -> Tuple[int, int]:
        try:
            bbox = g.textbbox((0, 0), text, font=font)
            return bbox[2] - bbox[0], bbox[3] - bbox[1]
        except Exception:
            return int(g.textlength(text, font=font)), getattr(font, "size", 14)

    def fit_font_for_width(text: str, max_width: int, base_font: ImageFont.ImageFont, min_size: int = 10) -> ImageFont.ImageFont:
        size = getattr(base_font, "size", 14) or 14
        size = int(size)
        while size >= min_size:
            f = try_load_font(size)
            if g.textlength(text, font=f) <= max_width:
                return f
            size -= 1
        return try_load_font(min_size)

    def draw_text_fit(text: str, x: int, y: int, max_width: int, base_font: ImageFont.ImageFont, fill: Tuple[int, int, int]) -> ImageFont.ImageFont:
        f = fit_font_for_width(text, max_width, base_font)
        g.text((x, y), text, font=f, fill=fill)
        return f

    def trim_to_width(text: str, max_width: int, font: ImageFont.ImageFont) -> str:
        if g.textlength(text, font=font) <= max_width:
            return text
        ell = "‚Ä¶"
        if g.textlength(ell, font=font) > max_width:
            return ""
        lo, hi = 0, len(text)
        ans = ""
        while lo <= hi:
            mid = (lo + hi) // 2
            cand = text[:mid] + ell
            if g.textlength(cand, font=font) <= max_width:
                ans = cand
                lo = mid + 1
            else:
                hi = mid - 1
        return ans
    # Project bar (Header left)
    proj_x0, proj_y0 = padding, padding
    header_right_w = int(W * 0.42)
    proj_x1, proj_y1 = W - padding - header_right_w - 12, proj_y0 + project_bar_h

    # (title drawn later after burndown)
    boards_n = max(1, boards_n)
    board_gap = 2
    board_seg_w = (proj_x1 - proj_x0 - (boards_n - 1) * board_gap) // boards_n
    bx = proj_x0
    focus_board_idx = 0
    focus_board_x0 = proj_x0
    focus_board_x1 = proj_x0 + board_seg_w
    # (timestamp drawn later once; avoid duplicate here)
    focus_board_x0 = proj_x0
    for i in range(boards_n):
        fill = col_board_focus if i == focus_board_idx else col_board_other
        g.rectangle([bx, proj_y0 + 6, bx + board_seg_w, proj_y1 - 6], fill=fill, outline=col_outline)
        if i == focus_board_idx:
            focus_board_x0, focus_board_x1 = bx, bx + board_seg_w
        bx += board_seg_w + board_gap

    # Sprints row constrained to the focused board x-range
    spr_y0 = proj_y1 + gap
    spr_y1 = spr_y0 + board_bar_h
    g.rectangle([focus_board_x0, spr_y0, focus_board_x1, spr_y1], fill=col_board_focus, outline=(60, 60, 60))

    sprints_n = max(1, sprints_n)
    sprint_gap = 2
    spr_total_w = focus_board_x1 - focus_board_x0
    # Precompute sprint total from data for ratio calc (avoid undefined total_cnt)
    try:
        _dtot = (data or {}).get("totals", {}) if isinstance(data, dict) else {}
        sprint_total_data = int(_dtot.get("subtasks", 0))
    except Exception:
        sprint_total_data = 0
    # Try to draw sprint width proportional to subtasks share (sprint vs project)
    spr_ratio: Optional[float] = None
    try:
        kpi_data = (extras or {}).get("kpis", {}) if extras else {}
        # current sprint subtasks total (prefer KPI, fallback to data)
        if isinstance(kpi_data, dict):
            sprint_total = int(kpi_data.get("sprintTotal") or sprint_total_data)
        else:
            sprint_total = sprint_total_data
        proj_total = None
        if extras and isinstance(extras.get("project_subtask_count"), dict):
            proj_total = int(extras["project_subtask_count"].get("total") or 0)
        if not proj_total:
            proj_total = int(kpi_data.get("projectTotal") or 0) if isinstance(kpi_data, dict) else 0
        if proj_total and proj_total > 0:
            spr_ratio = max(0.0, min(1.0, float(sprint_total) / float(proj_total)))
    except Exception:
        spr_ratio = None

    sx = focus_board_x0
    focus_s_x0 = sx
    focus_s_x1 = sx + spr_total_w
        # „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Çπ„Éó„É™„É≥„Éà„Åå1‰ª∂„ÅÆ„Åø ‚Üí Â∏Ø„Çí1Êú¨ÔºàActive Sprint Done/Remaining „ÅÆ2Ëâ≤Á©ç„ÅøÊ£íÔºâ
    if sprints_n == 1:
        # 1Êú¨„ÅÆÂ∏Ø„ÅßÂÆå‰∫Ü/Êú™ÂÆå‰∫Ü„ÇíË°®Á§∫
        g.rectangle([sx, spr_y0 + 4, sx + spr_total_w, spr_y1 - 4], fill=col_sprint_focus, outline=col_outline)
        focus_s_x0, focus_s_x1 = sx, sx + spr_total_w
        
        # Backlog„ÇíÂà•„ÅÆÂ∞è„Åï„Å™Ê®™„Éê„Éº„Å´Ë°®Á§∫
        try:
            kpi_data = (extras or {}).get("kpis", {}) if extras else {}
            project_open_total = int(kpi_data.get("projectOpenTotal", 0))
            sprint_open = int(kpi_data.get("sprintOpen", 0))  # Áõ¥Êé•sprintOpen„Çí‰ΩøÁî®
            backlog_open = max(0, project_open_total - sprint_open)
            
            if backlog_open > 0:
                # BacklogË°®Á§∫Áî®„ÅÆÂ∞è„Åï„Å™„Éê„ÉºÔºàÂ∑¶‰∏ä„Çπ„Éó„É™„É≥„ÉàÂ∏Ø„ÅÆ‰∏ãÔºâ
                backlog_y0 = spr_y1 + 2
                backlog_y1 = backlog_y0 + 12
                backlog_w = min(200, spr_total_w // 3)  # ÂπÖ„ÅØÂà∂Èôê
                g.rectangle([sx, backlog_y0, sx + backlog_w, backlog_y1], fill=(230, 230, 230), outline=col_outline)
                g.text((sx + 4, backlog_y0 + 1), f"Backlog: {backlog_open}", font=font_xs, fill=col_text)
        except Exception:
            pass
    elif spr_ratio is not None:
        # Ë§áÊï∞„Ç¢„ÇØ„ÉÜ„Ç£„ÉñÔºàÂ∞ÜÊù•Êã°ÂºµÔºâ„ÅÆÂ†¥Âêà„ÅÆ„ÅøÂâ≤ÂêàÂàÜÂâ≤
        cur_w = max(2, int(round(spr_total_w * spr_ratio)))
        other_w = max(0, spr_total_w - cur_w)
        g.rectangle([sx, spr_y0 + 4, sx + cur_w, spr_y1 - 4], fill=col_sprint_focus, outline=col_outline)
        if other_w > 0:
            g.rectangle([sx + cur_w, spr_y0 + 4, sx + cur_w + other_w, spr_y1 - 4], fill=col_sprint_other, outline=col_outline)
        focus_s_x0, focus_s_x1 = sx, sx + cur_w
    else:
        # Fallback to equal segments when ratio is unknown
        spr_seg_w = (spr_total_w - (sprints_n - 1) * sprint_gap) // sprints_n
        focus_s_idx = 0
        focus_s_x0 = sx
        focus_s_x1 = sx + spr_seg_w
        for i in range(sprints_n):
            fill = col_sprint_focus if i == focus_s_idx else col_sprint_other
            g.rectangle([sx, spr_y0 + 4, sx + spr_seg_w, spr_y1 - 4], fill=fill, outline=col_outline)
            if i == focus_s_idx:
                focus_s_x0, focus_s_x1 = sx, sx + spr_seg_w
            sx += spr_seg_w + sprint_gap

    # Tasks row constrained to the focused sprint x-range
    parents = data.get("parents", [])
    tasks: List[Dict[str, Any]] = []
    for p in parents:
        for st in p.get("subtasks", []) or []:
            tasks.append(st)

    task_y0 = spr_y1 + gap
    task_y1 = task_y0 + sprint_bar_h
    g.rectangle([focus_s_x0, task_y0, focus_s_x1, task_y1], fill=col_sprint_focus, outline=(60, 60, 60))

    n = max(1, len(tasks))
    task_gap = 2
    task_total_w = focus_s_x1 - focus_s_x0
    task_seg_w = (task_total_w - (n - 1) * task_gap) // n
    tx = focus_s_x0
    for t in tasks:
        done = bool(t.get("done")) if t.get("done") is not None else False
        fill = col_task_done if done else col_task_todo
        g.rectangle([tx, task_y0 + 3, tx + task_seg_w, task_y1 - 3], fill=fill, outline=None)
        tx += task_seg_w + task_gap

    # Summary bar (Done vs Not Done) with labels ‚Äî use data-based totals (consistency)
    totals = data.get("totals", {})
    done_cnt = int(totals.get("done", 0))
    total_cnt = int(totals.get("subtasks", max(1, len(tasks))))
    not_done_cnt = max(0, total_cnt - done_cnt)
    done_rate = (done_cnt / total_cnt) if total_cnt > 0 else 0.0

    sum_y0 = task_y1 + 14
    sum_y1 = sum_y0 + 26
    g.rectangle([focus_s_x0, sum_y0, focus_s_x1, sum_y1], fill=(245, 245, 245), outline=col_outline)
    done_w = int((focus_s_x1 - focus_s_x0) * done_rate)
    g.rectangle([focus_s_x0, sum_y0, focus_s_x0 + done_w, sum_y1], fill=col_task_done)
    g.rectangle([focus_s_x0 + done_w, sum_y0, focus_s_x1, sum_y1], fill=col_task_todo)
    # Headline above summary bar ‚Äî clarify unit (Â∞è„Çø„Çπ„ÇØ)
    headline = f"„Çπ„Éó„É™„É≥„Éà(Â∞è„Çø„Çπ„ÇØ): {total_cnt}‰ª∂ | ÂÆå‰∫Ü: {done_cnt} ({int(done_rate*100)}%)"
    head_x, head_y = focus_s_x0, sum_y0 - 20
    g.text((head_x, head_y), headline, font=font_md, fill=col_text)
    # Compute headline bounding box for collision checks
    try:
        hb = g.textbbox((head_x, head_y), headline, font=font_md)
    except Exception:
        hb = (head_x, head_y, head_x + int(g.textlength(headline, font=font_md)), head_y + getattr(font_md, "size", 14))

    # Numeric labels on segments
    def center_text(x0: int, x1: int, y: int, text: str, font: ImageFont.ImageFont, fill=col_text):
        tw, th = g.textlength(text, font=font), font.size
        cx = (x0 + x1) // 2 - int(tw // 2)
        g.text((cx, y), text, font=font, fill=fill)

    label_y = sum_y0 + 5
    done_label = f"{done_cnt} tasks ({int(done_rate*100)}%)"
    not_label = f"{not_done_cnt} tasks ({int((1-done_rate)*100)}%)"
    if done_w > g.textlength(done_label, font=font_sm) + 8:
        center_text(focus_s_x0, focus_s_x0 + done_w, label_y, done_label, font_sm, fill=(255,255,255))
    if (focus_s_x1 - (focus_s_x0 + done_w)) > g.textlength(not_label, font=font_sm) + 8:
        center_text(focus_s_x0 + done_w, focus_s_x1, label_y, not_label, font_sm, fill=(255,255,255))

    # Axis grid and labels (0,25,50,75,100)
    grid_y0 = sum_y1 + 10
    grid_y1 = grid_y0 + 1
    g.line([focus_s_x0, grid_y0, focus_s_x1, grid_y0], fill=col_outline, width=1)
    ticks = [0, 25, 50, 75, 100]
    for t in ticks:
        x = focus_s_x0 + int((focus_s_x1 - focus_s_x0) * (t / 100.0))
        g.line([x, grid_y0 - 5, x, grid_y0 + 5], fill=col_outline, width=1)
        # light vertical grid lines
        g.line([x, spr_y0, x, sum_y1], fill=col_grid, width=1)
        if axis_mode == "percent":
            g.text((x - 10, grid_y0 + 6), f"{t}%", font=font_sm, fill=col_text)
        else:
            # Convert percent into counts scale
            count_at_t = int(round(total_cnt * (t / 100.0)))
            g.text((x - 10, grid_y0 + 6), str(count_at_t), font=font_sm, fill=col_text)

    # Benchmark line (target done %)
    bx = focus_s_x0 + int((focus_s_x1 - focus_s_x0) * target_done_rate)
    g.line([bx, sum_y0 - 10, bx, sum_y1 + 10], fill=col_benchmark, width=2)
    # Place benchmark label; avoid collision with headline
    tgt_label = f"ÁõÆÊ®ô {int(target_done_rate*100)}%"
    tgt_pos_top = (bx + 4, sum_y0 - 18)
    try:
        tb = g.textbbox(tgt_pos_top, tgt_label, font=font_sm)
    except Exception:
        tw = int(g.textlength(tgt_label, font=font_sm))
        th = getattr(font_sm, "size", 12)
        tb = (tgt_pos_top[0], tgt_pos_top[1], tgt_pos_top[0] + tw, tgt_pos_top[1] + th)
    # Simple AABB intersect
    def _intersects(a, b):
        ax0, ay0, ax1, ay1 = a
        bx0, by0, bx1, by1 = b
        return not (ax1 < bx0 or bx1 < ax0 or ay1 < by0 or by1 < ay0)
    if _intersects(hb, tb):
        # Move below the bar if colliding
        g.text((bx + 4, sum_y1 + 4), tgt_label, font=font_sm, fill=col_benchmark)
    else:
        g.text(tgt_pos_top, tgt_label, font=font_sm, fill=col_benchmark)

    # (Removed prominent banner to avoid overlap with title area)

    # Header right: Burndown sparkline
    def draw_burndown_sparkline(x0: int, y0: int, w: int, h: int, bd: Optional[Dict[str, Any]]) -> None:
        if not bd:
            g.rectangle([x0, y0, x0 + w, y0 + h], outline=col_outline, fill=(250, 250, 250))
            g.text((x0 + 8, y0 + 8), "„Éá„Éº„Çø„Å™„Åó", font=font_sm, fill=(120, 120, 120))
            return
        series = bd.get("timeSeries") or []
        ideal = bd.get("ideal") or []
        if not series:
            g.rectangle([x0, y0, x0 + w, y0 + h], outline=col_outline, fill=(250, 250, 250))
            g.text((x0 + 8, y0 + 8), "„Éá„Éº„Çø„Å™„Åó", font=font_sm, fill=(120, 120, 120))
            return
        pad_left = 10
        pad_right = 10
        pad_bottom = 10
        pad_top = 28  # ‰∏äÈÉ®‰ΩôÁôΩ„ÇíÊã°Â§ßÔºà„Çø„Ç§„Éà„É´Ôºã„É©„Éô„É´ÂàÜÔºâ
        pad = 10  # ‰∫àÊ∏¨ÈÉ®ÂàÜ„Åß‰ΩøÁî®
        gx0, gy0 = x0, y0
        gx1, gy1 = x0 + w, y0 + h
        g.rectangle([gx0, gy0, gx1, gy1], outline=col_outline, fill=(250, 250, 250))
        # axes
        g.line([gx0 + pad_left, gy1 - pad_bottom, gx1 - pad_right, gy1 - pad_bottom], fill=col_outline)
        g.line([gx0 + pad_left, gy0 + pad_top, gx0 + pad_left, gy1 - pad_bottom], fill=col_outline)
        # scale
        # ÂÆüÁ∏æ„Éá„Éº„Çø„ÅØÂÖ®„Å¶„ÅÆtimeSeries„Éá„Éº„Çø„Çí„Ç∞„É©„Éï„Å´ÂèçÊò†
        filtered_series = series
        rems = [float(x.get("remaining") or 0.0) for x in filtered_series]
        maxv = max(rems) if rems else 1.0
        maxv = max(maxv, 1.0)
        n = len(filtered_series)
        def _get_date(i: int) -> Optional[str]:
            d = filtered_series[i].get("date") or filtered_series[i].get("day") or filtered_series[i].get("time")
            return fmt_date(str(d)) if d else None
        def pt(idx: int, val: float) -> Tuple[int, int]:
            if n <= 1:
                t = 0.0
            else:
                t = idx / (n - 1)
            X = int((gx0 + pad_left) + t * (w - pad_left - pad_right))
            Y = int((gy1 - pad_bottom) - (val / maxv) * (h - pad_top - pad_bottom))
            return X, Y
        # ideal dotted (legend: gray dotted); compute when missing
        if not ideal and n >= 2:
            start_rem = rems[0]
            ideal = [{"remaining": start_rem * (1 - i / (n - 1))} for i in range(n)]
        # build points
        pts_i = [pt(i, float(v.get("remaining") or 0.0)) for i, v in enumerate(ideal[:n])] if ideal else []
        pts = [pt(i, float(v.get("remaining") or 0.0)) for i, v in enumerate(filtered_series)]
        # shade gap between ideal and actual (red when behind => actual above ideal)
        if pts_i and pts and len(pts) == len(pts_i):
            for i in range(1, len(pts)):
                ax0, ay0 = pts[i-1]
                ax1, ay1 = pts[i]
                ix0, iy0 = pts_i[i-1]
                ix1, iy1 = pts_i[i]
                # vertical quads per segment
                poly = [(ax0, ay0), (ax1, ay1), (ix1, iy1), (ix0, iy0)]
                # determine if behind (actual remaining > ideal -> higher Y)
                behind = ((ay0 + ay1) / 2.0) > ((iy0 + iy1) / 2.0)
                shade = (255, 200, 200, 128) if behind else (200, 240, 200, 128)
                try:
                    # use separate overlay for alpha
                    overlay = Image.new("RGBA", (w, h), (0, 0, 0, 0))
                    og = ImageDraw.Draw(overlay)
                    og.polygon([(px - gx0, py - gy0) for (px, py) in poly], fill=shade, outline=None)
                    img.paste(overlay, (gx0, gy0), overlay)
                except Exception:
                    pass
        # draw ideal dotted
        if pts_i:
            for i in range(1, len(pts_i)):
                if i % 2 == 0:
                    g.line([pts_i[i-1], pts_i[i]], fill=(120, 120, 120), width=2)
        # actual solid
        for i in range(1, len(pts)):
            g.line([pts[i-1], pts[i]], fill=(0, 120, 210), width=3)
        # Title and its bbox for collision checks
        title_pos = (gx0 + pad_left, gy0 + 2)  # ‰∏äÈÉ®‰ΩôÁôΩÂÜÖ„Å´„Çø„Ç§„Éà„É´„ÇíÊèèÁîª
        title_txt = "„Éê„Éº„É≥„ÉÄ„Ç¶„É≥ÔºàÊú™ÂÆå‰∫Ü„Çø„Çπ„ÇØÊé®ÁßªÔºâ"
        g.text(title_pos, title_txt, font=font_md, fill=col_text)
        try:
            title_bb = g.textbbox(title_pos, title_txt, font=font_md)
        except Exception:
            title_bb = (title_pos[0], title_pos[1], title_pos[0] + int(g.textlength(title_txt, font=font_md)), title_pos[1] + getattr(font_md, "size", 14))
        # axis labels (Y ticks and X dates)
        for frac in (0.0, 0.5, 1.0):
            x = gx0 + pad_left
            y = int((gy1 - pad_bottom) - frac * (h - pad_top - pad_bottom))
            g.line([x - 4, y, x + 4, y], fill=col_outline)
            val = int(round(maxv * frac))
            g.text((x - 8 - g.textlength(str(val), font=font_sm), y - 6), str(val), font=font_sm, fill=col_text)
        if n >= 2:
            labels = [0, n // 2, n - 1]
            for idx in labels:
                lx, _ = pt(idx, 0)
                dlab = _get_date(idx)
                if dlab:
                    g.text((lx - 10, gy1 - pad_bottom + 2), dlab, font=font_sm, fill=col_text)
        # latest remaining label
        try:
            if pts:
                last_val = float(filtered_series[-1].get("remaining") or 0.0)
                lx, ly = pts[-1]
                lbl = f"ÊÆã: {last_val:.1f}"
                g.text((lx + 6, ly - 10), lbl, font=font_sm, fill=(0, 120, 210))
        except Exception:
            pass
        # forecast: simple linear regression on (i, remaining) -> predict zero
        try:
            import statistics as _stats
            xs = list(range(n))
            ys = rems
            # compute slope and intercept
            x_mean = sum(xs) / n
            y_mean = sum(ys) / n
            denom = sum((x - x_mean) ** 2 for x in xs) or 1.0
            slope = sum((x - x_mean) * (y - y_mean) for x, y in zip(xs, ys)) / denom
            intercept = y_mean - slope * x_mean
            # predict index where remaining ~ 0
            if slope < 0:
                t0 = -intercept / slope
            else:
                t0 = float('inf')
            # draw dashed forecast line from last index to t0
            if t0 != float('inf'):
                # sample M points between last and t0 (clamped)
                start = n - 1
                M = 20
                prev = None
                for j in range(M + 1):
                    t = start + (t0 - start) * (j / M)
                    yv = max(0.0, slope * t + intercept)
                    px, py = pt(int(round(t)), yv)
                    if prev is not None and j % 2 == 0:
                        g.line([prev, (px, py)], fill=(120, 0, 160), width=2)
                    prev = (px, py)
                # label predicted date and delay
                from datetime import datetime, timedelta
                # try to parse last date
                last_date_raw = series[-1].get("date") or series[-1].get("day") or series[-1].get("time")
                if last_date_raw and t0 != float('inf'):
                    try:
                        # assume daily cadence
                        base = datetime.strptime(str(series[0].get("date")), "%Y-%m-%d") if series[0].get("date") else datetime.today()
                        pred_date = base + timedelta(days=int(round(t0)))
                        status = "ÈÅÖÂª∂‰∫àÊ∏¨" if t0 > (n - 1) else "Èñì„Å´Âêà„ÅÜ‰∫àÊ∏¨"
                        pred_txt = f"‰∫àÊ∏¨ÂÆå‰∫Ü: {pred_date.strftime('%Y/%m/%d')} ({status})"
                        pred_pos = (gx0 + pad + 2, gy0 + 2)
                        # Avoid overlapping title; if intersect, move below title
                        try:
                            pred_bb = g.textbbox(pred_pos, pred_txt, font=font_sm)
                        except Exception:
                            pred_bb = (pred_pos[0], pred_pos[1], pred_pos[0] + int(g.textlength(pred_txt, font=font_sm)), pred_pos[1] + getattr(font_sm, "size", 12))
                        def _inter(a, b):
                            ax0, ay0, ax1, ay1 = a
                            bx0, by0, bx1, by1 = b
                            return not (ax1 < bx0 or bx1 < ax0 or ay1 < by0 or by1 < ay0)
                        if _inter(title_bb, pred_bb):
                            g.text((gx0 + pad + 2, title_bb[3] + 2), pred_txt, font=font_sm, fill=(120, 0, 160))
                        else:
                            g.text(pred_pos, pred_txt, font=font_sm, fill=(120, 0, 160))
                    except Exception:
                        alt_txt = "‰∫àÊ∏¨ÂÆå‰∫Ü: Ë®àÁÆó‰∏çÂèØ"
                        alt_pos = (gx0 + pad + 2, gy0 + 2)
                        try:
                            alt_bb = g.textbbox(alt_pos, alt_txt, font=font_sm)
                        except Exception:
                            alt_bb = (alt_pos[0], alt_pos[1], alt_pos[0] + int(g.textlength(alt_txt, font=font_sm)), alt_pos[1] + getattr(font_sm, "size", 12))
                        if not (alt_bb[1] < title_bb[3] and alt_bb[3] > title_bb[1] and alt_bb[2] > title_bb[0] and alt_bb[0] < title_bb[2]):
                            g.text(alt_pos, alt_txt, font=font_sm, fill=(120, 0, 160))
                        else:
                            g.text((gx0 + pad + 2, title_bb[3] + 2), alt_txt, font=font_sm, fill=(120, 0, 160))
        except Exception:
            pass

    # Position burndown and mini velocity side-by-side in header right
    bd_box_x0 = proj_x1 + 12
    bd_box_y0 = padding
    bd_box_h = 110
    bd_box_w = header_right_w // 2 - 6
    velmini_box_x0 = bd_box_x0 + bd_box_w + 12
    velmini_box_w = header_right_w - bd_box_w - 12
    bd_data = (extras or {}).get("burndown") if extras else None
    draw_burndown_sparkline(bd_box_x0, bd_box_y0, bd_box_w, bd_box_h, bd_data)
    # mini velocity chart (reserved_h is dynamic based on KPI text height)
    def draw_velocity_mini(x0: int, y0: int, w: int, h: int, vel: Optional[Dict[str, Any]], reserved_h: int) -> None:
        # Apply adapter to handle both new and old velocity formats
        vel = adapt_velocity_data(vel)
        if not vel:
            g.rectangle([x0, y0, x0 + w, y0 + h], outline=col_outline, fill=(250, 250, 250))
            g.text((x0 + 8, y0 + 8), "„Éá„Éº„Çø„Å™„Åó", font=font_sm, fill=(120, 120, 120))
            return
        pts = vel.get("points") or []
        if not isinstance(pts, list) or len(pts) < 2:
            g.rectangle([x0, y0, x0 + w, y0 + h], outline=col_outline, fill=(250, 250, 250))
            g.text((x0 + 8, y0 + 8), "„Éô„É≠„Ç∑„ÉÜ„Ç£„ÅØ„Çπ„Éó„É™„É≥„Éà2‰ª•Èôç„Å´Ë°®Á§∫", font=font_sm, fill=(120, 120, 120))
            return
        pad = 10
        gx0, gy0 = x0, y0
        gx1, gy1 = x0 + w, y0 + h
        g.rectangle([gx0, gy0, gx1, gy1], outline=col_outline, fill=(250, 250, 250))
        # bars
        n = max(1, len(pts))
        bar_gap = 4
        bar_w = max(4, (w - 2 * pad - (n - 1) * bar_gap) // max(1, n))
        values = [float(p.get("points") or 0.0) for p in pts]
        avg = float(vel.get("avgPoints") or 0.0)
        maxv = max(values + [avg, 1.0])
        for i, v in enumerate(values):
            bx = gx0 + pad + i * (bar_w + bar_gap)
            by = gy1 - pad
            bh = int((v / maxv) * (h - 2 * pad - max(0, reserved_h)))
            g.rectangle([bx, by - bh, bx + bar_w, by], fill=(80, 170, 240), outline=col_outline)
        # avg line
        if maxv > 0:
            y_avg = int((gy1 - pad) - (avg / maxv) * (h - 2 * pad - max(0, reserved_h)))
            g.line([gx0 + pad, y_avg, gx1 - pad, y_avg], fill=(120, 0, 120), width=2)
        # draw a small caption at bottom-left to avoid header overlap
        g.text((gx0 + pad, gy1 - pad - 14), "Velocity", font=font_sm, fill=col_text)

    vel_data_hdr = (extras or {}).get("velocity") if extras else None
    # header metrics ‚Äî emphasize progress vs target, avoid zero by falling back to data totals
    try:
        kpis_hdr = (extras or {}).get("kpis", {}) if extras else {}
        proj_total = int(kpis_hdr.get("projectTotal", 0))
        # fallback to subtask totals for sprint numbers to ensure consistency
        sprint_total_kpi = int(kpis_hdr.get("sprintTotal", 0))
        sprint_done_kpi = int(kpis_hdr.get("sprintDone", 0))
        sprint_total_fb = total_cnt
        sprint_done_fb = done_cnt
        sprint_total = sprint_total_kpi or sprint_total_fb
        sprint_done = sprint_done_kpi or sprint_done_fb
        done_pct = int(round(100 * (sprint_done / max(1, sprint_total))))
        tgt_pct = int(round(100 * target_done_rate))
        tx = velmini_box_x0 + 10
        ty = bd_box_y0 + 6
        label = f"ÈÄ≤Êçó {done_pct}% / ÁõÆÊ®ô {tgt_pct}%"
        max_text_w = velmini_box_w - 18
        # Pre-fit fonts to compute reserved height for chart
        f1 = fit_font_for_width(label, max_text_w, font_lg)
        f2 = fit_font_for_width(
            f"„Éó„É≠„Ç∏„Çß„ÇØ„Éà:{proj_total} | „Çπ„Éó„É™„É≥„Éà(Â∞è„Çø„Çπ„ÇØ):{sprint_total} ÂÆå‰∫Ü:{sprint_done}",
            max_text_w,
            font_sm,
        )
        h1 = text_wh(label, f1)[1]
        line2 = f"„Éó„É≠„Ç∏„Çß„ÇØ„Éà:{proj_total} | „Çπ„Éó„É™„É≥„Éà(Â∞è„Çø„Çπ„ÇØ):{sprint_total} ÂÆå‰∫Ü:{sprint_done}"
        h2 = text_wh(line2, f2)[1]
        # Dedicated KPI panel above mini-velocity
        reserved_h = h1 + 4 + h2 + 10  # inner paddings
        # Ensure we leave room for the mini velocity chart
        min_vel_h = 40
        if reserved_h > bd_box_h - min_vel_h:
            reserved_h = max(28, bd_box_h - min_vel_h)
        # Draw KPI panel box
        g.rectangle([velmini_box_x0, bd_box_y0, velmini_box_x0 + velmini_box_w, bd_box_y0 + reserved_h], outline=col_outline, fill=(255, 255, 255))
        used_font = draw_text_fit(label, tx, ty, max_text_w, font_lg, (col_danger if done_pct < tgt_pct else col_ok))
        ty2 = ty + text_wh(label, used_font)[1] + 4
        draw_text_fit(line2, tx, ty2, max_text_w, font_sm, col_text)
        # Draw mini velocity below KPI panel
        mv_y0 = bd_box_y0 + reserved_h + 6
        mv_h = max(min_vel_h, bd_box_h - reserved_h - 6)
        draw_velocity_mini(velmini_box_x0, mv_y0, velmini_box_w, mv_h, vel_data_hdr, 0)
    except Exception:
        pass
    # Timestamp will be drawn at footer (moved from header to avoid collisions)

    # Title with sprint name and date range (Japanese formatting)
    title = "„Çπ„Éó„É™„É≥„Éà"
    if sprint_name:
        title = f"„Çπ„Éó„É™„É≥„Éà {sprint_name}"
    d0 = fmt_date(sprint_start) if sprint_start else None
    d1 = fmt_date(sprint_end) if sprint_end else None
    if d0 and d1:
        title = f"{title} ({d0} - {d1})"
    # draw safely within canvas (avoid negative y)
    g.text((proj_x0, max(4, proj_y0 - 2)), title, font=font_lg, fill=col_text)

    # Annotation for high not-done ratio and remember its bottom to avoid overlap with next blocks
    annotation_bottom = sum_y1
    if (1 - done_rate) >= 0.4:
        ann_text = f"Êú™ÂÆå‰∫Ü„Åå{int((1-done_rate)*100)}%„Å®È´ò„ÅÑ"
        ann_x = focus_s_x0
        ann_y = sum_y1 + 36
        g.text((ann_x, ann_y), ann_text, font=font_md, fill=col_danger)
        annotation_bottom = ann_y + text_wh(ann_text, font_md)[1]

    # Left column blocks below header: Velocity and Status Distribution
    left_col_x0 = proj_x0
    # Push left column below annotation if needed
    left_col_y0 = max(grid_y0 + 40, annotation_bottom + 8)
    left_col_w = proj_x1 - proj_x0
    
    # Adapter function to handle both old and new velocity data formats
    def adapt_velocity_data(vel: Optional[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """Convert new velocity format to old format for backward compatibility."""
        if not vel:
            return None
        
        # If already in old format, return as-is
        if "points" in vel and "avgPoints" in vel:
            return vel
        
        # Convert new format to old format
        if "history" in vel and "avg" in vel:
            points = []
            for h in vel.get("history", []):
                points.append({
                    "sprintId": h.get("id"),
                    "sprintName": h.get("name"),
                    "points": h.get("points", 0.0)
                })
            
            return {
                "board": vel.get("board"),
                "fieldId": vel.get("fieldId", "customfield_10016"),  # fallback
                "points": points,
                "avgPoints": vel.get("avg", 0.0)
            }
        
        return vel
    
    # Velocity bars
    def draw_velocity(x0: int, y0: int, w: int, h: int, vel: Optional[Dict[str, Any]]) -> int:
        # Apply adapter to handle both new and old velocity formats
        vel = adapt_velocity_data(vel)
        if not vel:
            return y0
        pts = vel.get("points") or []
        avg = float(vel.get("avgPoints") or 0.0)
        if not isinstance(pts, list):
            return y0
        pad = 10
        gx0, gy0 = x0, y0
        gx1, gy1 = x0 + w, y0 + h
        g.rectangle([gx0, gy0, gx1, gy1], outline=col_outline, fill=(250, 250, 250))
        g.text((gx0 + pad, gy0 + 2), "Velocity (last sprints)", font=font_md, fill=col_text)
        # bars
        n = max(1, len(pts))
        bar_gap = 6
        bar_w = max(6, (w - 2 * pad - (n - 1) * bar_gap) // max(1, n))
        maxv = max([float(p.get("points") or 0.0) for p in pts] + [avg, 1.0])
        for i, p in enumerate(pts):
            v = float(p.get("points") or 0.0)
            bx = gx0 + pad + i * (bar_w + bar_gap)
            by = gy1 - pad
            bh = int((v / maxv) * (h - 2 * pad))
            g.rectangle([bx, by - bh, bx + bar_w, by], fill=(80, 170, 240), outline=col_outline)
        # avg line
        if maxv > 0:
            y_avg = int((gy1 - pad) - (avg / maxv) * (h - 2 * pad))
            g.line([gx0 + pad, y_avg, gx1 - pad, y_avg], fill=(120, 0, 120), width=2)
            g.text((gx0 + pad + 4, y_avg - 14), f"avg {avg:.1f}", font=font_sm, fill=(120, 0, 120))
        # target line (dashed)
        try:
            target = float(os.getenv("VELOCITY_TARGET", ""))
        except Exception:
            target = None  # type: ignore
        if maxv > 0 and target:
            y_t = int((gy1 - pad) - (float(target) / maxv) * (h - 2 * pad))
            # dashed line
            x = gx0 + pad
            while x < gx1 - pad:
                x2 = min(x + 10, gx1 - pad)
                g.line([x, y_t, x2, y_t], fill=(200, 0, 0), width=2)
                x += 16
            g.text((gx0 + pad + 4, y_t + 2), f"target {float(target):.1f}", font=font_sm, fill=(200, 0, 0))
        return gy1

    vel_box_h = 140
    vel_data = (extras or {}).get("velocity") if extras else None
    vel_y1 = draw_velocity(left_col_x0, left_col_y0, left_col_w, vel_box_h, vel_data)

    # Status distribution stacked bar
    def draw_status_dist(x0: int, y0: int, w: int, h: int, st: Optional[Dict[str, Any]]) -> int:
        if not st:
            return y0
        bys = st.get("byStatus") or []
        total = float(st.get("total") or 0.0)
        if total <= 0 or not bys:
            return y0
        g.text((x0, y0 - 18), "„Çπ„ÉÜ„Éº„Çø„ÇπÂàÜÂ∏É", font=font_md, fill=col_text)
        gx0, gy0 = x0, y0
        gx1, gy1 = x0 + w, y0 + h
        g.rectangle([gx0, gy0, gx1, gy1], outline=col_outline, fill=(250, 250, 250))
        # palette rotate
        palette = [
            (200, 200, 200),
            (253, 174, 97),
            (44, 162, 95),
            (49, 130, 189),
            (141, 160, 203),
            (230, 85, 13),
        ]
        x = gx0 + 10
        y = gy0 + 10
        hbar = h - 20
        for i, row in enumerate(bys):
            cnt = float(row.get("count") or 0.0)
            frac = cnt / total
            wseg = int((w - 20) * frac)
            col = palette[i % len(palette)]
            g.rectangle([x, y, x + wseg, y + hbar], fill=col, outline=col_outline)
            label_full = f"{row.get('status')} ({int(frac*100)}%)"
            # If label doesn't fit, fallback to percentage only
            label = label_full if (wseg >= g.textlength(label_full, font=font_sm) + 8) else f"{int(frac*100)}%"
            g.text((x + 4, y + hbar//2 - 8), label, font=font_sm, fill=(30, 30, 30))
            x += wseg
        return gy1

    st_box_y0 = vel_y1 + 24
    st_box_h = 60
    st_data = (extras or {}).get("status_counts") if extras else None
    st_y1 = draw_status_dist(left_col_x0, st_box_y0, left_col_w, st_box_h, st_data)

    # Time-in-Status heatmap (avg days per status)
    def draw_time_in_status_heatmap(x0: int, y0: int, w: int, h: int, tis: Optional[Dict[str, Any]]) -> int:
        if not tis:
            return y0
        per_issue = tis.get("perIssue") or []
        if not per_issue:
            return y0
        # aggregate average days per status
        sum_map: Dict[str, float] = {}
        cnt_map: Dict[str, int] = {}
        vals_map: Dict[str, List[float]] = {}

        # normalize function to merge same meanings (e.g., IN_PROGRESS vs In Progress)
        def norm_status(name: str) -> str:
            s = str(name or "").strip()
            if not s:
                return s
            key = s.lower().replace(" ", "_")
            # common mappings
            aliases = {
                "in_progress": "In Progress",
                "inprogress": "In Progress",
                "in-progress": "In Progress",
                "todo": "To Do",
                "to_do": "To Do",
                "to-do": "To Do",
                "in_review": "In Review",
                "inreview": "In Review",
                "qa": "QA",
                "quality_assurance": "QA",
                "done": "Done",
                "review": "Review",
            }
            return aliases.get(key, s)
        for row in per_issue:
            by = row.get("byStatus") or {}
            for st, days in by.items():
                try:
                    d = float(days)
                except Exception:
                    d = 0.0
                label = norm_status(st)
                sum_map[label] = sum_map.get(label, 0.0) + d
                cnt_map[label] = cnt_map.get(label, 0) + 1
                vals_map.setdefault(label, []).append(d)
        if not sum_map:
            return y0
        items = [(k, (sum_map[k] / max(1, cnt_map.get(k, 1)))) for k in sum_map.keys()]
        # sort by avg days desc
        items.sort(key=lambda x: -x[1])
        # limit to max statuses for display (default 6)
        try:
            max_statuses = int(os.getenv("TIS_MAX_STATUSES", "6"))
        except Exception:
            max_statuses = 6
        items = items[:max(1, max_statuses)]
        g.text((x0, y0 - 18), "Â∑•Á®ãÊªûÂú®ÊôÇÈñìÔºàÊó•Ôºâ(avg | median)", font=font_md, fill=col_text)
        # layout grid 1 row, N columns (small heatmap)
        pad = 8
        n = len(items)
        if n <= 0:
            return y0
        cell_w = max(60, (w - 2 * pad) // n)
        cell_h = h - 2 * pad - 18
        gx0, gy0 = x0, y0
        gx1, gy1 = x0 + w, y0 + h
        g.rectangle([gx0, gy0, gx1, gy1], outline=col_outline, fill=(250, 250, 250))
        # color scale (green -> yellow -> red)
        max_days = max([v for _, v in items] + [1.0])
        def color_for(value: float) -> Tuple[int, int, int]:
            t = min(1.0, value / max_days)
            # 0 -> green(44,162,95), 1 -> red(215,48,39) via yellow
            # simple linear blend green->red
            g0 = (44, 162, 95)
            r1 = (215, 48, 39)
            r = int(g0[0] + (r1[0] - g0[0]) * t)
            gch = int(g0[1] + (r1[1] - g0[1]) * t)
            b = int(g0[2] + (r1[2] - g0[2]) * t)
            return (r, gch, b)
        x = x0 + pad
        y = y0 + pad + 12
        for name, avgd in items:
            col = color_for(avgd)
            g.rectangle([x, y, x + cell_w - 6, y + cell_h], fill=col, outline=col_outline)
            # median label
            try:
                vals = vals_map.get(name, [])
                med = 0.0
                if vals:
                    svals = sorted(vals)
                    m = len(svals)
                    med = (svals[m//2] if m % 2 == 1 else (svals[m//2 - 1] + svals[m//2]) / 2.0)
                g.text((x + 4, y - 14), f"{avgd:.1f}/{med:.1f}d", font=font_sm, fill=col_text)
            except Exception:
                g.text((x + 4, y - 14), f"{avgd:.1f}d", font=font_sm, fill=col_text)
            # label (status name) under cell if„Çπ„Éö„Éº„Çπ
            g.text((x + 4, y + cell_h + 2), name[:12], font=font_sm, fill=col_text)
            x += cell_w
        return gy1

    tis_box_y0 = st_y1 + 24
    tis_box_h = 100
    tis_data = (extras or {}).get("time_in_status") if extras else None
    tis_y1 = draw_time_in_status_heatmap(left_col_x0, tis_box_y0, left_col_w, tis_box_h, tis_data)

    # Right column: KPI cards and Assignee workload
    right_x0 = bd_box_x0
    right_y0 = bd_box_y0 + bd_box_h + 16
    right_w = header_right_w

    def draw_kpi_cards(x0: int, y0: int, w: int, h: int, kpis: Dict[str, int]) -> int:
        pad = 8
        cols = 3
        rows = 2
        gap = 10
        card_w = (w - (cols - 1) * gap)
        card_w = card_w // cols
        card_h = h
        # six KPI cards
        order = [
            ("projectOpenTotal", "„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÜÖÊú™ÂÆå‰∫Ü„Çø„Çπ„ÇØÊï∞", (200, 100, 40)),  # Êú™ÂÆå‰∫Ü„Çø„Çπ„ÇØÊï∞„Å´Â§âÊõ¥
            ("sprintOpen", "„Çπ„Éó„É™„É≥„ÉàÂÜÖÊú™ÂÆå‰∫Ü„Çø„Çπ„ÇØÊï∞", (60, 160, 60)),  # Á∑è„Çø„Çπ„ÇØÊï∞„Åã„ÇâÊú™ÂÆå‰∫Ü„Çø„Çπ„ÇØÊï∞„Å´Â§âÊõ¥
            ("unassignedCount", "ÊãÖÂΩìËÄÖÊú™ÂÆö„Çø„Çπ„ÇØÊï∞", (27, 158, 119)),  # ÂÆå‰∫Ü„Çø„Çπ„ÇØÊï∞„Åã„ÇâÊãÖÂΩìËÄÖÊú™ÂÆö„Çø„Çπ„ÇØÊï∞„Å´Â§âÊõ¥
            ("overdue", "ÊúüÈôêÈÅµÂÆà‰∏≠‚úÖ", (60, 140, 60)),
            ("dueSoon", "Ê≥®ÊÑè:7Êó•‰ª•ÂÜÖÊúüÈôê", (230, 140, 0)),
            ("highPriorityTodo", "Ë¶ÅÊ≥®ÊÑè„Çø„Çπ„ÇØ(È´òÂÑ™ÂÖàÂ∫¶)", (200, 120, 60)),
        ]
        x = x0
        y = y0
        for idx, (key, title, col) in enumerate(order):
            v = int(kpis.get(key, 0))
            g.rectangle([x, y, x + card_w, y + card_h], outline=col_outline, fill=(245, 245, 245))
            g.text((x + 8, y + 6), title, font=font_sm, fill=col_text)
            # Positive phrasing for zero overdue
            if key == "overdue" and v == 0:
                txt = "0"
                col_draw = col_ok
            elif key == "sprintOpen":
                # Êú™ÂÆå‰∫Ü / Á∑èÊï∞ „ÅÆÂΩ¢Âºè„ÅßË°®Á§∫
                sprint_total = int(kpis.get("sprintTotal", 0))
                txt = f"{v}/{sprint_total}"
                col_draw = col
            elif key == "projectOpenTotal":
                # „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÜÖÊú™ÂÆå‰∫Ü / Á∑èÊï∞ „ÅÆÂΩ¢Âºè„ÅßË°®Á§∫
                project_total = int(kpis.get("projectTotal", 0))
                txt = f"{v}/{project_total}"
                col_draw = col
            else:
                txt = str(v)
                col_draw = col
            g.text((x + 8, y + 28), txt, font=try_load_font(24), fill=col_draw)
            # advance grid
            if (idx + 1) % cols == 0:
                x = x0
                y += card_h + gap
            else:
                x += card_w + gap
        return y

    kpi_h = 64
    kpi_data = (extras or {}).get("kpis") if extras else {}
    kpi_y1 = draw_kpi_cards(right_x0, right_y0, right_w, kpi_h, kpi_data or {})

    def draw_workload(x0: int, y0: int, w: int, h: int, wl: Optional[Dict[str, Any]]) -> int:
        if not wl:
            return y0
        rows = wl.get("byAssignee") or []
        if not rows:
            return y0
        g.text((x0, y0 - 18), "ÊãÖÂΩìËÄÖÂà•„ÉØ„Éº„ÇØ„É≠„Éº„ÉâÔºàÊú™ÂÆå‰∫ÜÔºâ", font=font_md, fill=col_text)
        pad = 8
        topn = min(8, len(rows))
        rows = sorted(rows, key=lambda r: -int(r.get("notDone") or 0))[:topn]
        maxv = max([int(r.get("notDone") or 0) for r in rows] + [1])
        bar_h = max(14, (h - 2 * pad - (topn - 1) * 6) // max(1, topn))
        y = y0
        for r in rows:
            name = str(r.get("name"))
            v = int(r.get("notDone") or 0)
            bw = int((w - 2 * pad) * (v / maxv))
            g.rectangle([x0, y, x0 + bw, y + bar_h], fill=(255, 180, 70), outline=col_outline)
            g.text((x0 + 6, y + 2), f"{name} ({v})", font=font_sm, fill=(20, 20, 20))
            y += bar_h + 6
        return y

    wl_h = 220
    wl_data = (extras or {}).get("workload") if extras else None
    wl_y1 = draw_workload(right_x0, kpi_y1 + 20, right_w, wl_h, wl_data)
    wl_y2 = wl_y1 + wl_h

    # Footer: Evidence table
    def draw_evidence(x0: int, y0: int, w: int, h: int, ev: Optional[List[Dict[str, Any]]]) -> None:
        g.text((x0, y0 - 18), "ÈáçË¶Å„Ç®„Éì„Éá„É≥„ÇπÔºàTopÔºâ", font=font_md, fill=col_text)
        if not ev:
            return
        # header
        # Ë™≤È°åÂàó„Å´„Çµ„Éû„É™„Éº„ÇÇ‰ΩµË®ò„Åô„Çã„Åü„ÇÅÂπÖ„ÇíÂ∫É„Åí„Çã
        # Ë™≤È°å/ÊãÖÂΩìËÄÖ/„Çπ„ÉÜ„Éº„Çø„Çπ/ÁêÜÁî±/„É™„É≥„ÇØ„ÅÆÊØîÁéá„ÇíË™øÊï¥„Åó„Å¶„É™„É≥„ÇØÂàó„ÅÆÈñãÂßã‰ΩçÁΩÆ„ÇíÂ∑¶„Å∏ÂØÑ„Åõ„Çã
        # „É™„É≥„ÇØ„ÅØÁü≠Á∏ÆË°®Á§∫„Åô„Çã„Åå„ÄÅÈñãÂßã‰ΩçÁΩÆ„ÅåÂ∑¶„Å´Êù•„Çã„Çà„ÅÜÊúÄÂæå„ÅÆ2Âàó„ÇíÁ∏Æ„ÇÅ„Çã
        # ÂàóÂπÖ: „É™„É≥„ÇØ„ÇíÊúÄÂ∑¶„ÉªÊúÄÂ§ßÂπÖ„ÄÅ‰ªñ„ÅØÊúÄÂ∞èÈôê
        col_w = [int(w*0.40), int(w*0.18), int(w*0.12), int(w*0.18), int(w*0.12)]
        headers = ["„É™„É≥„ÇØ", "Ë™≤È°å", "ÊãÖÂΩìËÄÖ", "„Çπ„ÉÜ„Éº„Çø„Çπ", "ÈáçË¶Å„Å™ÁêÜÁî±"]
        cx = x0
        y = y0
        g.rectangle([x0, y0, x0 + w, y0 + h], outline=col_outline, fill=(250, 250, 250))
        # header row
        y_row = y + 6
        cx = x0 + 8
        for i, head in enumerate(headers):
            g.text((cx, y_row), head, font=font_sm, fill=col_text)
            cx += col_w[i]
        y_row += 20
        # data rows
        for e in ev:
            cx = x0 + 8
            # „É™„É≥„ÇØÔºàÂÖ®Ë°®Á§∫„ÄÅ„ÅØ„ÅøÂá∫„ÅóÊôÇ„ÅØÊú´Â∞æ...Ôºâ
            raw_link = str(e.get('link', '')).replace('https://', '').replace('http://', '')
            link = raw_link
            while g.textlength(link, font=font_sm) > (col_w[0] - 12) and len(link) > 4:
                link = link[:-1]
            if g.textlength(link, font=font_sm) > (col_w[0] - 12):
                link = link[:max(0, len(link)-3)] + '...'
            g.text((cx, y_row), link, font=font_sm, fill=col_text)
            cx += col_w[0]
            # Ë™≤È°å: key + summary (truncated)
            key_sum = f"{e.get('key', '')} {e.get('summary', '')[:20]}".strip()
            g.text((cx, y_row), key_sum, font=font_sm, fill=col_text)
            cx += col_w[1]
            # ÊãÖÂΩìËÄÖ
            assignee = e.get('assignee', '')[:10]
            g.text((cx, y_row), assignee, font=font_sm, fill=col_text)
            cx += col_w[2]
            # „Çπ„ÉÜ„Éº„Çø„Çπ
            status = e.get('status', '')[:10]
            g.text((cx, y_row), status, font=font_sm, fill=col_text)
            cx += col_w[3]
            # ÈáçË¶Å„Å™ÁêÜÁî±
            why = e.get('why', '')[:20]
            g.text((cx, y_row), why, font=font_sm, fill=col_text)
            cx += col_w[4]
            y_row += 16
            if y_row > y0 + h - 10:
                break  # prevent overflow
    ev_box_x0 = left_col_x0
    ev_box_y0 = max(tis_y1, st_y1) + 40
    ev_box_w = W - padding - ev_box_x0
    ev_box_h = 140
    evidence = (extras or {}).get("evidence") if extras else None
    draw_evidence(ev_box_x0, ev_box_y0, ev_box_w, ev_box_h, evidence)

    # (moved overlay panel below after caption lines are drawn)

    # Caption (What / So what / Next action) ‚Äî compact 3 lines with data provenance
    cap_y = ev_box_y0 + ev_box_h + 16
    # sprint meta
    sprint_label = (f"„Çπ„Éó„É™„É≥„Éà {sprint_name}" if sprint_name else "„Çπ„Éó„É™„É≥„Éà")
    d0 = fmt_date(sprint_start) if sprint_start else None
    d1 = fmt_date(sprint_end) if sprint_end else None
    if d0 and d1:
        sprint_label = f"{sprint_label} ({d0}-{d1})"
    # KPI numbers if available
    kpi_data = (extras or {}).get("kpis", {}) if extras else {}
    sprint_total = int(kpi_data.get("sprintTotal", total_cnt))
    sprint_done = int(kpi_data.get("sprintDone", done_cnt))
    # time-in-status Review avg (days)
    review_avg = None
    tis_obj = (extras or {}).get("time_in_status") if extras else None
    try:
        per_issue = (tis_obj or {}).get("perIssue") or []
        sum_map: Dict[str, float] = {}
        cnt_map: Dict[str, int] = {}
        for row in per_issue:
            by = row.get("byStatus") or {}
            for st, days in by.items():
                d = float(days) if days is not None else 0.0
                sum_map[st] = sum_map.get(st, 0.0) + d
                cnt_map[st] = cnt_map.get(st, 0) + 1
        # find Review-like key
        if sum_map:
            # pick exact 'Review' else any containing 'Review'
            key_candidates = [k for k in sum_map.keys() if str(k).lower() == "review"] or [k for k in sum_map.keys() if "review" in str(k).lower()]
            if key_candidates:
                k0 = key_candidates[0]
                review_avg = sum_map[k0] / max(1, cnt_map.get(k0, 1))
    except Exception:
        pass
    # Build context for Gemini summary
    risks_data = (extras or {}).get("risks", {}) if extras else {}
    # Action recommendations based on data
    action_suggestions = []
    hp = int(risks_data.get("highPriorityTodo", 0))
    od = int(risks_data.get("overdue", 0))
    ds = int(risks_data.get("dueSoon", 0))
    if done_rate < target_done_rate:
        action_suggestions.append("„É¨„Éì„É•„ÉºÊãÖÂΩì„ÅÆÂ¢óÂì°/‰∏¶ÂàóÂåñ„Åß„Çπ„É´„Éº„Éó„ÉÉ„ÉàÊîπÂñÑ")
    if hp > 0:
        action_suggestions.append(f"È´òÂÑ™ÂÖàÂ∫¶Êú™ÁùÄÊâã {hp}‰ª∂„Å´Âç≥ÊôÇÊãÖÂΩìÂâ≤ÂΩì")
    if od > 0:
        action_suggestions.append(f"ÊúüÈôêË∂ÖÈÅé {od}‰ª∂„ÅÆ„Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥")
    if ds > 0:
        action_suggestions.append(f"ÊúüÈôêÊé•Ëøë {ds}‰ª∂„ÅÆÂÑ™ÂÖàÈ†Ü‰ΩçÂÜçÁ¢∫Ë™ç")
    
    # Êñ∞„Åó„ÅÑcontext„Ç≠„Éº„ÅÆË®àÁÆó
    try:
        kpi_data = (extras or {}).get("kpis", {}) if extras else {}
        project_open_total = int(kpi_data.get("projectOpenTotal", 0))
        sprint_open = sprint_total - sprint_done
        backlog_open = max(0, project_open_total - sprint_open)
        
        # VelocityÈñ¢ÈÄ£„ÅÆË®àÁÆó
        velocity_data = (extras or {}).get("velocity") if extras else None
        velocity_avg = 0.0
        last_velocity = 0.0
        if velocity_data:
            if "avg" in velocity_data:  # Êñ∞ÂΩ¢Âºè
                velocity_avg = float(velocity_data.get("avg", 0.0))
                history = velocity_data.get("history", [])
                if history:
                    last_velocity = float(history[0].get("points", 0.0))
            else:  # ÊóßÂΩ¢Âºè
                velocity_avg = float(velocity_data.get("avgPoints", 0.0))
                points = velocity_data.get("points", [])
                if points:
                    last_velocity = float(points[0].get("points", 0.0))
        
        # ÊÆãÊó•Êï∞„ÅÆË®àÁÆóÔºà„Çπ„Éó„É™„É≥„ÉàÁµÇ‰∫ÜÊó•„Åã„ÇâÔºâ
        remaining_days = 0
        if sprint_end:
            try:
                from datetime import datetime, date
                if "T" in sprint_end:
                    end_date = datetime.fromisoformat(sprint_end.replace("Z", "+00:00")).date()
                else:
                    end_date = datetime.strptime(sprint_end, "%Y-%m-%d").date()
                today = date.today()
                remaining_days = max(0, (end_date - today).days)
            except Exception:
                remaining_days = 0
        
        # ÂøÖË¶Å„Å™Êó•Ê¨°Ê∂àÂåñÊï∞„ÅÆË®àÁÆó
        required_daily_burn = None
        if remaining_days > 0:
            import math
            target_remaining = max(0, int(target_done_rate * sprint_total) - sprint_done)
            required_daily_burn = math.ceil(target_remaining / remaining_days) if target_remaining > 0 else 0
        
        # ÂÆüÁ∏æÊó•Ê¨°Ê∂àÂåñÊï∞ÔºàÁõ¥Ëøë3Êó•„ÅÆÂπ≥ÂùáÔºâ
        actual_daily_burn = None
        burndown_data = (extras or {}).get("burndown") if extras else None
        if burndown_data:
            time_series = burndown_data.get("timeSeries", [])
            if len(time_series) >= 4:  # ÊúÄ‰Ωé4Êó•ÂàÜ„ÅÆ„Éá„Éº„Çø„ÅåÂøÖË¶Å
                try:
                    burn_lookback_days = int(os.getenv("BURN_LOOKBACK_DAYS", "3"))
                    recent_series = time_series[-burn_lookback_days-1:]  # ÊúÄÊñ∞N+1Êó•ÂàÜ
                    if len(recent_series) >= 2:
                        total_burned = 0.0
                        for i in range(len(recent_series) - 1):
                            prev_remaining = float(recent_series[i].get("remaining", 0.0))
                            curr_remaining = float(recent_series[i+1].get("remaining", 0.0))
                            daily_burn = max(0.0, prev_remaining - curr_remaining)
                            total_burned += daily_burn
                        actual_daily_burn = total_burned / max(1, len(recent_series) - 1)
                except Exception:
                    actual_daily_burn = None
        
        # „Éú„Éà„É´„Éç„ÉÉ„ÇØÂ∑•Á®ã„ÅÆÁâπÂÆö
        bottleneck_status = None
        bottleneck_days = 0.0
        tis_data = (extras or {}).get("time_in_status") if extras else None
        if tis_data:
            per_issue = tis_data.get("perIssue", [])
            if per_issue:
                # ÂêÑ„Çπ„ÉÜ„Éº„Çø„Çπ„ÅÆÂπ≥ÂùáÊªûÂú®ÊôÇÈñì„ÇíË®àÁÆó
                status_totals = {}
                status_counts = {}
                for issue in per_issue:
                    by_status = issue.get("byStatus", {})
                    for status, days in by_status.items():
                        try:
                            days_float = float(days)
                            status_totals[status] = status_totals.get(status, 0.0) + days_float
                            status_counts[status] = status_counts.get(status, 0) + 1
                        except Exception:
                            continue
                
                # ÊúÄ„ÇÇÊôÇÈñì„Åå„Åã„Åã„Çã„Çπ„ÉÜ„Éº„Çø„Çπ„ÇíÁâπÂÆö
                max_avg_days = 0.0
                for status in status_totals:
                    avg_days = status_totals[status] / max(1, status_counts[status])
                    if avg_days > max_avg_days:
                        max_avg_days = avg_days
                        bottleneck_status = status
                        bottleneck_days = avg_days
        
    except Exception:
        project_open_total = 0
        sprint_open = sprint_total - sprint_done
        backlog_open = 0
        velocity_avg = 0.0
        last_velocity = 0.0
        remaining_days = 0
        required_daily_burn = None
        actual_daily_burn = None
        bottleneck_status = None
        bottleneck_days = 0.0

    context_for_ai = {
        "sprint_label": sprint_label,
        "sprint_total": sprint_total,
        "sprint_done": sprint_done,
        "done_percent": round(done_rate * 100, 1),
        "target_percent": int(target_done_rate * 100),
        "remaining_days": remaining_days,
        "required_daily_burn": required_daily_burn,
        "actual_daily_burn": actual_daily_burn,
        "sprint_open": sprint_open,
        "backlog_open": backlog_open,
        "velocity_avg": velocity_avg,
        "last_velocity": last_velocity,
        "bottleneck_status": bottleneck_status,
        "bottleneck_days": bottleneck_days,
        "review_avg_days": review_avg,
        "overdue": int(risks_data.get("overdue", 0)),
        "due_soon": int(risks_data.get("dueSoon", 0)),
        "high_priority_unstarted": int(risks_data.get("highPriorityTodo", 0)),
        "suggested_actions": action_suggestions,
        "top_evidence": (extras or {}).get("evidence", []) or [],
        "project_open_total": project_open_total,
    }
    raw_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    gemini_key = _sanitize_api_key(raw_key)
    # Gemini diagnostics
    _log_on = (os.getenv("DASHBOARD_LOG", "1").lower() in ("1", "true", "yes"))
    _gemini_disabled = os.getenv("GEMINI_DISABLE", "").lower() in ("1", "true", "yes")
    ai = None
    if gemini_key and not _gemini_disabled and genai is not None:
        if os.getenv("GEMINI_DEBUG", "").lower() in ("1", "true", "yes") and _log_on:
            masked = f"{gemini_key[:4]}...{gemini_key[-4:]}" if len(gemini_key) >= 8 else "(set)"
            if raw_key and raw_key != gemini_key:
                print("- AIË¶ÅÁ¥Ñ: API„Ç≠„Éº„ÇíÊ≠£Ë¶èÂåñ„Åó„Åæ„Åó„ÅüÔºàÈùûASCII„ÇÑ‰ΩôÂàÜ„Å™Ë®òÂè∑„ÇíÈô§ÂéªÔºâ")
            print(f"- AIË¶ÅÁ¥Ñ: „Ç≠„ÉºÊ§úÂá∫ {masked}")
        ai = maybe_gemini_summary(gemini_key, context_for_ai)
        if _log_on:
            if ai:
                print("- AIË¶ÅÁ¥Ñ: Gemini ÊàêÂäü (ÂÖ®ÊñáÂèñÂæó)")
            else:
                print("- AIË¶ÅÁ¥Ñ: Gemini Âëº„Å≥Âá∫„ÅóÂ§±Êïó„Åæ„Åü„ÅØÁ©∫ÂøúÁ≠î")
        try:
            if isinstance(extras, dict):
                extras["ai_full_text"] = ai if isinstance(ai, str) else None
        except Exception:
            pass
    else:
        if _log_on:
            if _gemini_disabled:
                print("- AIË¶ÅÁ¥Ñ: ÁÑ°ÂäπÂåñ (GEMINI_DISABLE)")
            elif not gemini_key:
                print("- AIË¶ÅÁ¥Ñ: Êú™Ë®≠ÂÆö (GEMINI_API_KEY/GOOGLE_API_KEY „Å™„Åó)")
            else:
                print("- AIË¶ÅÁ¥Ñ: „É©„Ç§„Éñ„É©„É™Êú™Â∞éÂÖ• (google-generativeai)")
    # Image caption remains deterministic and data-driven; AI full text goes to markdown
    what = f"What: {sprint_label} ‚Äî Â∞è„Çø„Çπ„ÇØ {total_cnt}‰ª∂, ÂÆå‰∫Ü {done_cnt} ({int((done_cnt/max(1,total_cnt))*100)}%). (data: sprint_subtasks_total={total_cnt}, sprint_subtasks_done={done_cnt})"
    if done_rate < target_done_rate:
        if review_avg is not None:
            sowhat = f"So what: ÁõÆÊ®ô{int(target_done_rate*100)}%Êú™ÈÅî„ÄÅ„É¨„Éì„É•„ÉºÊªûÁïô (data: time_in_status[Review].avg={review_avg:.1f}d)"
        else:
            sowhat = f"So what: ÁõÆÊ®ô{int(target_done_rate*100)}%Êú™ÈÅî"
    else:
        sowhat = "So what: „Éô„É≠„Ç∑„ÉÜ„Ç£ÂÆâÂÆö„ÄÅË®àÁîªÈÄö„Çä"
    hp = int(risks_data.get("highPriorityTodo", 0))
    nexta = f"Next: È´òÂÑ™ÂÖàÂ∫¶Êú™ÂÆå‰∫Ü{hp}‰ª∂„ÅÆÂâ≤ÂΩì„Å®„É¨„Éì„É•„ÉºÊãÖÂΩìÂ¢óÂì°"
    g.text((proj_x0, cap_y), what, font=font_sm, fill=col_text)
    g.text((proj_x0, cap_y + 16), sowhat, font=font_sm, fill=col_text)
    g.text((proj_x0, cap_y + 32), nexta, font=font_sm, fill=col_text)

    # AI summary overlay panel (wrapped text in image) ‚Äî runs after caption to avoid NameError
    try:
        overlay_enabled = os.getenv("AI_OVERLAY_IN_IMAGE", "1").lower() in ("1", "true", "yes")
        ai_text = (extras or {}).get("ai_full_text") if extras else None
        if overlay_enabled and isinstance(ai_text, str) and ai_text.strip():
            # Keep the full AI summary content without truncation
            try:
                import re as _re
                # Remove excessive whitespace but keep all content
                ai_text = _re.sub(r"\r", "", ai_text)
                ai_text = _re.sub(r"\n[ \t]*\n+", "\n", ai_text)
            except Exception:
                pass
            panel_x0 = proj_x0
            panel_w = W - padding - panel_x0
            # Place directly under evidence to guarantee space
            panel_y0 = ev_box_y0 + ev_box_h + 12
            footer_reserve = 28
            panel_h = max(72, H - padding - footer_reserve - panel_y0)
            if panel_h >= 24:
                g.rectangle([panel_x0, panel_y0, panel_x0 + panel_w, panel_y0 + panel_h], outline=col_outline, fill=(245, 245, 245))
                title = "AIË¶ÅÁ¥Ñ (Gemini)"
                g.text((panel_x0 + 8, panel_y0 + 6), title, font=font_md, fill=col_text)

                def wrap_text(text: str, max_width: int, font: ImageFont.ImageFont) -> List[str]:
                    lines: List[str] = []
                    for raw in text.split("\n"):
                        s = raw.rstrip("\r")
                        if not s:
                            lines.append("")
                            continue
                        buf = ""
                        for ch in s:
                            cand = buf + ch
                            try:
                                # ÁµµÊñáÂ≠ó„ÇÑÁâπÊÆäÊñáÂ≠ó„ÅÆÊèèÁîªÂπÖ„ÇíÂÆâÂÖ®„Å´Ë®àÁÆó
                                if g.textlength(cand, font=font) <= max_width:
                                    buf = cand
                                else:
                                    if buf:
                                        lines.append(buf)
                                        buf = ch
                                    else:
                                        lines.append(ch)
                                        buf = ""
                            except Exception:
                                # ÊñáÂ≠óÂπÖË®àÁÆó„Å´Â§±Êïó„Åó„ÅüÂ†¥Âêà„ÅØÂÆâÂÖ®„Å´Âá¶ÁêÜ
                                if len(buf) > 0:
                                    lines.append(buf)
                                    buf = ch
                                else:
                                    buf = ch
                        if buf != "":
                            lines.append(buf)
                    return lines



                content_x = panel_x0 + 8
                content_y = panel_y0 + 6 + text_wh(title, font_md)[1] + 4
                content_w = panel_w - 16
                content_font = font_sm
                line_h = max(14, text_wh("A", content_font)[1])
                max_lines_by_height = max(1, (panel_h - (content_y - panel_y0) - 8) // line_h)
                try:
                    max_lines_cap = int(os.getenv("AI_OVERLAY_MAX_LINES", "18"))
                except Exception:
                    max_lines_cap = 18
                max_lines = max(1, min(max_lines_by_height, max_lines_cap))
                total_wrapped = wrap_text(ai_text.strip(), content_w, content_font)
                # Draw within one image; truncate with ellipsis if overflow
                y = content_y
                shown = 0
                for ln in total_wrapped:
                    if shown + 1 < max_lines:
                        g.text((content_x, y), ln, font=content_font, fill=col_text)
                        y += line_h
                        shown += 1
                    else:
                        # last visible line with ellipsis
                        last = ln
                        ell = " ‚Ä¶"
                        while last and g.textlength(last + ell, font=content_font) > content_w:
                            last = last[:-1]
                        g.text((content_x, y), (last + ell) if last else "‚Ä¶", font=content_font, fill=col_text)
                        break
    except Exception:
        pass

    # Footer timestamp (bottom-right)
    try:
        import datetime as _dt
        ts = _dt.datetime.now().strftime("ÁîüÊàê: %Y/%m/%d %H:%M")
        tw = g.textlength(ts, font=font_sm)
        g.text((W - padding - tw, H - padding - getattr(font_sm, "size", 12)), ts, font=font_sm, fill=(120, 120, 120))
    except Exception:
        pass

    img.save(output_path, format="PNG", dpi=(150, 150))


def main() -> int:
    maybe_load_dotenv()
    JIRA_DOMAIN = os.getenv("JIRA_DOMAIN", "").rstrip("/")
    email = os.getenv("JIRA_EMAIL")
    api_token = os.getenv("JIRA_API_TOKEN")
    boards_n = 1
    sprints_n = 1
    sprint_name = None
    sprint_start = None
    sprint_end = None
    board = None
    sprint = None
    auth: Optional[HTTPBasicAuth] = None
    if JIRA_DOMAIN and email and api_token:
        auth = HTTPBasicAuth(email, api_token)
        code_b, board, _ = resolve_board(JIRA_DOMAIN, auth)
        if code_b == 200 and board:
            proj_key = os.getenv("JIRA_PROJECT_KEY") or try_infer_project_key_from_board(JIRA_DOMAIN, auth, board) or None
            boards_n = max(1, count_boards_for_project(JIRA_DOMAIN, auth, proj_key))
            try:
                bid = int(board.get("id"))
                sprints_n = max(1, count_active_sprints_for_board(JIRA_DOMAIN, auth, bid))
                sprint = resolve_active_sprint(JIRA_DOMAIN, auth, bid)
                if sprint:
                    sprint_name = sprint.get("name")
                    sprint_start = sprint.get("startDate")
                    sprint_end = sprint.get("endDate")
            except Exception:
                sprints_n = 1
    base_dir = Path(os.getenv("OUTPUT_DIR") or Path(__file__).resolve().parent)
    subtasks_script = str(base_dir / "queries" / "jira_list_sprint_subtasks.py")
    data = get_json_from_script(subtasks_script)
    out_path = str(base_dir / "sprint_overview.png")
    axis_mode = os.getenv("AXIS_MODE", "percent").lower()  # 'percent' or 'count'
    try:
        target_done_rate = float(os.getenv("TARGET_DONE_RATE", "0.8"))
    except Exception:
        target_done_rate = 0.8
    # Fetch extra metrics for dashboard
    extras: Dict[str, Any] = {}
    try:
        # A. Burndown
        bd_args = ["--unit", os.getenv("BURNDOWN_UNIT", "issues")]
        extras["burndown"] = get_json_from_script_args(str(base_dir / "queries" / "jira_q_burndown.py"), bd_args)
    except Exception:
        extras["burndown"] = None
    try:
        # B. Velocity
        vel_args: List[str] = []
        n_sprints = os.getenv("N_SPRINTS", "6")
        if n_sprints:
            vel_args += ["--n", n_sprints]
        extras["velocity"] = get_json_from_script_args(str(base_dir / "queries" / "jira_q_velocity_history.py"), vel_args)
    except Exception as e:
        print(f"Error getting velocity data: {e}")
        extras["velocity"] = None
    try:
        # B2. Project sprint count (all states)
        extras["project_sprint_count"] = get_json_from_script_args(str(base_dir / "queries" / "jira_count_project_sprints.py"), [])
    except Exception:
        extras["project_sprint_count"] = None
    try:
        # C. Status distribution (sprint scope, approx)
        sc_args = ["--scope", "sprint", "--mode", os.getenv("STATUS_COUNTS_MODE", "approx")]
        extras["status_counts"] = get_json_from_script_args(str(base_dir / "queries" / "jira_q_status_counts.py"), sc_args)
    except Exception:
        extras["status_counts"] = None
    try:
        # D. Time-in-Status (for evidence calc; unit days)
        tis_args = ["--scope", "sprint", "--unit", os.getenv("TIS_UNIT", "days")]
        tis = get_json_from_script_args(str(base_dir / "queries" / "jira_q_time_in_status.py"), tis_args)
        extras["time_in_status"] = tis
    except Exception:
        extras["time_in_status"] = None
    try:
        # E. Assignee workload
        wl_args = ["--scope", "sprint"]
        extras["workload"] = get_json_from_script_args(str(base_dir / "queries" / "jira_q_assignee_workload.py"), wl_args)
    except Exception:
        extras["workload"] = None
    # F. KPI cards and risks
    kpis: Dict[str, int] = {"projectTotal": 0, "sprintTotal": 0, "sprintOpen": 0, "sprintDone": 0, "unassignedCount": 0, "overdue": 0, "dueSoon": 0, "highPriorityTodo": 0}
    risks: Dict[str, int] = {"overdue": 0, "dueSoon": 0, "highPriorityTodo": 0}
    try:
        od_args = ["--scope", "sprint"]
        overdue = get_json_from_script_args(str(base_dir / "queries" / "jira_q_overdue_count.py"), od_args)
        risks["overdue"] = int(overdue.get("overdueCount") or 0)
        kpis["overdue"] = risks["overdue"]
    except Exception:
        pass
    try:
        ds_days = os.getenv("DUE_SOON_DAYS", "7")
        ds_args = ["--scope", "sprint", "--days", ds_days]
        due_soon = get_json_from_script_args(str(base_dir / "queries" / "jira_q_due_soon_count.py"), ds_args)
        risks["dueSoon"] = int(due_soon.get("dueSoonCount") or 0)
    except Exception:
        pass
    try:
        # High priority unstarted count
        if auth and sprint and JIRA_DOMAIN:
            sid = sprint.get("id")
            pri = os.getenv("HIGH_PRIORITIES", "Highest,High")
            pri_list = ",".join([f'"{p.strip()}"' for p in pri.split(",") if p.strip()])
            jql = f"Sprint={sid} AND type in subTaskIssueTypes() AND priority in ({pri_list}) AND statusCategory = \"To Do\""
            code_c, cnt, _ = approximate_count(JIRA_DOMAIN, auth, jql)
            if not (code_c == 200 and cnt is not None):
                code_c, cnt, _ = search_count(JIRA_DOMAIN, auth, jql)
            if code_c == 200 and cnt is not None:
                risks["highPriorityTodo"] = int(cnt)
    except Exception:
        pass
    # Unassigned count
    try:
        unassigned_data = get_json_from_script_args(str(base_dir / "queries" / "jira_q_unassigned_count.py"), ["--scope", "sprint"])
        if isinstance(unassigned_data, dict):
            kpis["unassignedCount"] = int(unassigned_data.get("unassignedCount", 0))
    except Exception:
        pass
    # Enforce risks to be subtask-based (override with subtask-only JQL when possible)
    try:
        if auth and sprint and JIRA_DOMAIN:
            sid = sprint.get("id")
            # Overdue (subtasks only)
            jql_od = f"Sprint={sid} AND type in subTaskIssueTypes() AND duedate < endOfDay() AND statusCategory != \"Done\""
            code_od, cnt_od, _ = approximate_count(JIRA_DOMAIN, auth, jql_od)
            if not (code_od == 200 and cnt_od is not None):
                code_od, cnt_od, _ = search_count(JIRA_DOMAIN, auth, jql_od)
            if code_od == 200 and cnt_od is not None:
                risks["overdue"] = int(cnt_od)
                kpis["overdue"] = risks["overdue"]
            # Due soon (subtasks only)
            ds_days = os.getenv("DUE_SOON_DAYS", "7")
            jql_ds = (
                f"Sprint={sid} AND type in subTaskIssueTypes() "
                f"AND duedate >= startOfDay() AND duedate <= endOfDay(+{ds_days}d) "
                f"AND statusCategory != \"Done\""
            )
            code_ds, cnt_ds, _ = approximate_count(JIRA_DOMAIN, auth, jql_ds)
            if not (code_ds == 200 and cnt_ds is not None):
                code_ds, cnt_ds, _ = search_count(JIRA_DOMAIN, auth, jql_ds)
            if code_ds == 200 and cnt_ds is not None:
                risks["dueSoon"] = int(cnt_ds)
    except Exception:
        pass
    # projectTotal / sprintTotal counts (subtask-based for sprint)
    try:
        # Sprint totals from aggregated data (subtasks only)
        try:
            totals_obj = (data or {}).get("totals", {}) if isinstance(data, dict) else {}
            kpis["sprintTotal"] = int(totals_obj.get("subtasks", 0))
            kpis["sprintDone"] = int(totals_obj.get("done", 0))
            kpis["sprintOpen"] = int(totals_obj.get("notDone", 0))  # Êú™ÂÆå‰∫Ü„Çø„Çπ„ÇØÊï∞
        except Exception:
            pass
        if auth and JIRA_DOMAIN:
            # Prefer dedicated query script for project subtasks
            try:
                ps = get_json_from_script_args(str(base_dir / "queries" / "jira_count_project_subtasks.py"), [])
                if isinstance(ps, dict):
                    extras["project_subtask_count"] = ps
                    kpis["projectTotal"] = int(ps.get("total", 0))
                    kpis["projectOpenTotal"] = int(ps.get("openTotal", 0))  # Êú™ÂÆå‰∫Ü„Çø„Çπ„ÇØÊï∞
                    # projectAllSubtasks„Çí‰øùÊåÅÔºà„Ç∞„É©„ÉïÈùûË°®Á§∫„ÄÅ„Éá„Éº„Çø„ÅÆ„ÅøÔºâ
                    extras["projectAllSubtasks"] = int(ps.get("total", 0))
            except Exception:
                # Fallback to inline JQL if script fails
                proj_key = os.getenv("JIRA_PROJECT_KEY") or try_infer_project_key_from_board(JIRA_DOMAIN, auth, board) or None
                if proj_key:
                    jql_proj_sub = f"project={proj_key} AND type in subTaskIssueTypes()"
                    code_pt, cnt_pt, _ = approximate_count(JIRA_DOMAIN, auth, jql_proj_sub)
                    if not (code_pt == 200 and cnt_pt is not None):
                        code_pt, cnt_pt, _ = search_count(JIRA_DOMAIN, auth, jql_proj_sub)
                    if code_pt == 200 and cnt_pt is not None:
                        kpis["projectTotal"] = int(cnt_pt)
                        extras["projectAllSubtasks"] = int(cnt_pt)  # ÂÖ®„Çø„Çπ„ÇØÊï∞‰øùÊåÅ
                        # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÔºöÊú™ÂÆå‰∫ÜÊï∞„ÇÇÂèñÂæó
                        jql_proj_open = f"project={proj_key} AND type in subTaskIssueTypes() AND statusCategory != \"Done\""
                        code_po, cnt_po, _ = approximate_count(JIRA_DOMAIN, auth, jql_proj_open)
                        if not (code_po == 200 and cnt_po is not None):
                            code_po, cnt_po, _ = search_count(JIRA_DOMAIN, auth, jql_proj_open)
                        if code_po == 200 and cnt_po is not None:
                            kpis["projectOpenTotal"] = int(cnt_po)
    except Exception:
        pass
    # carry risks into KPI deck as well
    kpis["overdue"] = max(kpis.get("overdue", 0), risks.get("overdue", 0))
    kpis["dueSoon"] = risks.get("dueSoon", 0)
    kpis["highPriorityTodo"] = risks.get("highPriorityTodo", 0)
    extras["kpis"] = kpis
    extras["risks"] = risks

    # G. Evidence table: Top N by longest time-in-status (days)
    try:
        ev_list: List[Dict[str, Any]] = []
        tis = extras.get("time_in_status") or {}
        unit = ((tis.get("window") or {}).get("unit") or "days")
        denom = 1.0  # already in days
        per_issue = tis.get("perIssue") or []
        for row in per_issue:
            key = row.get("key")
            by = row.get("byStatus") or {}
            days = sum(float(v) for v in by.values()) / (1.0 if unit == "days" else 24.0)
            ev_list.append({"key": key, "days": days})
        # sort and take top N
        ev_list = [e for e in ev_list if e.get("key")]
        ev_list.sort(key=lambda r: -float(r.get("days") or 0.0))
        topn = int(os.getenv("EVIDENCE_TOP_N", "5"))
        ev_list = ev_list[:topn]
        # fetch current status for these keys
        if auth and JIRA_DOMAIN and ev_list:
            keys_csv = ",".join([str(e["key"]) for e in ev_list])
            url = f"{JIRA_DOMAIN}/rest/api/3/search"
            fields = "summary,status,assignee,priority,duedate"
            params = {"jql": f"key in ({keys_csv})", "fields": fields, "maxResults": topn}
            code_s, data_s, _ = api_get(url, auth, params=params)
            detail_map: Dict[str, Dict[str, Any]] = {}
            if code_s == 200 and data_s:
                for iss in (data_s.get("issues") or []):
                    flds = iss.get("fields") or {}
                    detail_map[iss.get("key")] = {
                        "summary": flds.get("summary") or "",
                        "status": ((flds.get("status") or {}).get("name") or ""),
                        "assignee": ((flds.get("assignee") or {}).get("displayName") or ""),
                        "priority": ((flds.get("priority") or {}).get("name") or ""),
                        "duedate": flds.get("duedate") or "",
                    }
            # attach status, assignee, why and link
            dom = JIRA_DOMAIN.rstrip("/")
            for e in ev_list:
                k = e.get("key")
                det = detail_map.get(k, {})
                e["summary"] = det.get("summary", "")
                e["status"] = det.get("status", "")
                e["assignee"] = det.get("assignee", "")
                # why heuristic
                why = []
                try:
                    dd = det.get("duedate")
                    if dd:
                        # overdue if past today
                        import datetime as _dt
                        today = _dt.date.today()
                        ddd = _dt.datetime.strptime(dd, "%Y-%m-%d").date()
                        if ddd < today:
                            why.append("overdue")
                        elif (ddd - today).days <= int(os.getenv("DUE_SOON_DAYS", "7")):
                            why.append("due soon")
                except Exception:
                    pass
                pr = str(det.get("priority", ""))
                if pr.lower() in [p.strip().lower() for p in (os.getenv("HIGH_PRIORITIES", "Highest,High").split(","))]:
                    why.append("high priority")
                if float(e.get("days") or 0) >= 5.0:
                    why.append("long stay")
                e["why"] = ", ".join(why)
                e["link"] = f"{dom}/browse/{k}"
        # Optionally enhance 'why' with Gemini (one-liner) while keeping safe fallback
        try:
            raw_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
            gemini_key = _sanitize_api_key(raw_key)
            if gemini_key and ev_list:
                ai_reasons = maybe_gemini_justify_evidences(gemini_key, ev_list)
                if ai_reasons:
                    for e in ev_list:
                        k = e.get("key")
                        if k and ai_reasons.get(k):
                            e["why"] = ai_reasons[k]
        except Exception:
            pass
        extras["evidence"] = ev_list
    except Exception:
        extras["evidence"] = None

    # --- Logging (concise summaries) ---
    try:
        log_enabled = (os.getenv("DASHBOARD_LOG", "1").lower() in ("1", "true", "yes"))
        if log_enabled:
            print("[Dashboard] „Éá„Éº„ÇøÂèñÂæó„Çµ„Éû„É™„Éº")
            try:
                totals = data.get("totals", {}) if isinstance(data, dict) else {}
                print(f"- Â∞è„Çø„Çπ„ÇØ: ÂêàË®à {int(totals.get('subtasks', 0))}, ÂÆå‰∫Ü {int(totals.get('done', 0))}, Êú™ÂÆå‰∫Ü {int(totals.get('subtasks', 0)) - int(totals.get('done', 0))}")
            except Exception:
                pass
            # Burndown
            bd = extras.get("burndown")
            if isinstance(bd, dict):
                try:
                    ts = bd.get("timeSeries") or []
                    first = float((ts[0] or {}).get("remaining", 0.0)) if ts else 0.0
                    last = float((ts[-1] or {}).get("remaining", 0.0)) if ts else 0.0
                    print(f"- Burndown: unit={bd.get('unit')}, total={bd.get('total')}, days={len(ts)}, ÊÆã(Âßã‚ÜíÁµÇ) {first:.1f}‚Üí{last:.1f}")
                except Exception:
                    print("- Burndown: ÂèñÂæóÂ§±Êïó„Åæ„Åü„ÅØ„Éá„Éº„Çø„Å™„Åó")
            else:
                print("- Burndown: „Éá„Éº„Çø„Å™„Åó")
            # Velocity
            vel = extras.get("velocity")
            if isinstance(vel, dict):
                try:
                    # Handle new velocity format directly for display
                    if "history" in vel:
                        # New format: convert for display
                        history = vel.get("history", [])
                        avg_points = vel.get("avg", 0.0)
                        tail = [float(h.get("points", 0.0)) for h in history[-3:]]
                        print(f"- Velocity: avg={avg_points}, sprints={len(history)}, last={tail}")
                    else:
                        # Old format: use directly
                        pts = vel.get("points") or []
                        tail = [float(p.get("points") or 0.0) for p in pts[-3:]]
                        print(f"- Velocity: avg={vel.get('avgPoints')}, sprints={len(pts)}, last={tail}")
                except Exception as e:
                    print(f"- Velocity: ÂèñÂæóÂ§±Êïó„Åæ„Åü„ÅØ„Éá„Éº„Çø„Å™„Åó ({e})")
            else:
                print("- Velocity: „Éá„Éº„Çø„Å™„Åó")
            # Status counts
            sc = extras.get("status_counts")
            if isinstance(sc, dict):
                try:
                    total = int(sc.get("total", 0))
                    bys = sc.get("byStatus") or []
                    print(f"- „Çπ„ÉÜ„Éº„Çø„ÇπÂàÜÂ∏É: total={total}, Á®ÆÈ°û={len(bys)}")
                except Exception:
                    print("- „Çπ„ÉÜ„Éº„Çø„ÇπÂàÜÂ∏É: ÂèñÂæóÂ§±Êïó")
            else:
                print("- „Çπ„ÉÜ„Éº„Çø„ÇπÂàÜÂ∏É: „Éá„Éº„Çø„Å™„Åó")
            # Time in Status
            tis = extras.get("time_in_status")
            if isinstance(tis, dict):
                try:
                    per_issue = tis.get("perIssue") or []
                    print(f"- Â∑•Á®ãÊªûÂú®ÊôÇÈñì: issues={len(per_issue)}")
                except Exception:
                    print("- Â∑•Á®ãÊªûÂú®ÊôÇÈñì: ÂèñÂæóÂ§±Êïó")
            else:
                print("- Â∑•Á®ãÊªûÂú®ÊôÇÈñì: „Éá„Éº„Çø„Å™„Åó")
            # Workload
            wl = extras.get("workload")
            if isinstance(wl, dict):
                try:
                    rows = wl.get("byAssignee") or []
                    names = [str(r.get("name")) for r in rows[:3]]
                    print(f"- „ÉØ„Éº„ÇØ„É≠„Éº„Éâ: ÊãÖÂΩìËÄÖ={len(rows)}, top3={names}")
                except Exception:
                    print("- „ÉØ„Éº„ÇØ„É≠„Éº„Éâ: ÂèñÂæóÂ§±Êïó")
            else:
                print("- „ÉØ„Éº„ÇØ„É≠„Éº„Éâ: „Éá„Éº„Çø„Å™„Åó")
            # KPIs / Risks
            k = extras.get("kpis") or {}
            r = extras.get("risks") or {}
            try:
                print(f"- KPI: projectTotal={k.get('projectTotal')}, sprintTotal={k.get('sprintTotal')}, sprintOpen={k.get('sprintOpen')}, unassignedCount={k.get('unassignedCount')}")
                print(f"- „É™„Çπ„ÇØ: overdue={r.get('overdue')}, dueSoon={r.get('dueSoon')}, highPriorityTodo={r.get('highPriorityTodo')}")
            except Exception:
                pass
            # Project subtasks (detailed)
            psc2 = extras.get("project_subtask_count")
            if isinstance(psc2, dict):
                try:
                    print(f"- „Éó„É≠„Ç∏„Çß„ÇØ„Éà(Â∞è„Çø„Çπ„ÇØ): total={psc2.get('total')}, done={psc2.get('done')}, notDone={psc2.get('notDone')}")
                except Exception:
                    pass
            # Project sprint counts
            psc = extras.get("project_sprint_count")
            if isinstance(psc, dict):
                try:
                    bys = psc.get("byState", {}) or {}
                    print(f"- „Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅÆ„Çπ„Éó„É™„É≥„ÉàÊï∞: total={psc.get('total')} (active={bys.get('active')}, future={bys.get('future')}, closed={bys.get('closed')})")
                except Exception:
                    pass
            # Evidence
            ev = extras.get("evidence")
            if isinstance(ev, list):
                try:
                    keys = [e.get("key") for e in ev[:5] if e.get("key")]
                    print(f"- „Ç®„Éì„Éá„É≥„ÇπTopN: {len(ev)} ‰ª∂, keys={keys}")
                except Exception:
                    print("- „Ç®„Éì„Éá„É≥„Çπ: ÂèñÂæóÂ§±Êïó")
            elif ev is None:
                print("- „Ç®„Éì„Éá„É≥„Çπ: „Éá„Éº„Çø„Å™„Åó")
    except Exception:
        # „É≠„Ç∞„ÅØÂ§±Êïó„Åó„Å¶„ÇÇ„ÉÄ„ÉÉ„Ç∑„É•„Éú„Éº„ÉâÁîüÊàê„ÇíÁ∂ôÁ∂ö
        pass

    draw_png(out_path, data, boards_n, sprints_n, sprint_name, sprint_start, sprint_end, axis_mode, target_done_rate, extras)
    # Also emit a concise Markdown report with evidence and risks
    try:
        ts = __import__("datetime").datetime.now().strftime("%Y-%m-%d %H:%M")
        kpis = extras.get("kpis", {})
        risks = extras.get("risks", {})
        tis = extras.get("time_in_status", {}) or {}
        # compute review avg again for text
        review_avg = None
        try:
            per_issue = (tis or {}).get("perIssue") or []
            sum_map: Dict[str, float] = {}
            cnt_map: Dict[str, int] = {}
            for row in per_issue:
                by = row.get("byStatus") or {}
                for st, days in by.items():
                    d = float(days) if days is not None else 0.0
                    sum_map[st] = sum_map.get(st, 0.0) + d
                    cnt_map[st] = cnt_map.get(st, 0) + 1
            if sum_map:
                key_candidates = [k for k in sum_map.keys() if str(k).lower() == "review"] or [k for k in sum_map.keys() if "review" in str(k).lower()]
                if key_candidates:
                    k0 = key_candidates[0]
                    review_avg = sum_map[k0] / max(1, cnt_map.get(k0, 1))
        except Exception:
            pass
        sprint_label = sprint.get("name") if sprint else "Sprint"
        if sprint and sprint.get("startDate") and sprint.get("endDate"):
            sprint_label = f"{sprint_label} ({sprint.get('startDate')}‚Äî{sprint.get('endDate')})"
        sprint_total = int(kpis.get("sprintTotal", 0))
        sprint_done = int(kpis.get("sprintDone", 0))
        target_pct = int(target_done_rate * 100)
        overdue_cnt = int(risks.get("overdue", 0))
        due_soon_cnt = int(risks.get("dueSoon", 0))
        hp_cnt = int(risks.get("highPriorityTodo", 0))
        # Risk keys
        overdue_keys: List[str] = []
        due_soon_keys: List[str] = []
        hp_keys: List[str] = []
        if auth and JIRA_DOMAIN and sprint:
            sid = sprint.get("id")
            if overdue_cnt:
                overdue_keys = search_issue_keys(
                    JIRA_DOMAIN,
                    auth,
                    f"Sprint={sid} AND type in subTaskIssueTypes() AND duedate < endOfDay() AND statusCategory != \"Done\"",
                    10,
                )
            if due_soon_cnt:
                days = os.getenv("DUE_SOON_DAYS", "7")
                due_soon_keys = search_issue_keys(
                    JIRA_DOMAIN,
                    auth,
                    f"Sprint={sid} AND type in subTaskIssueTypes() AND duedate >= startOfDay() AND duedate <= endOfDay(+{days}d) AND statusCategory != \"Done\"",
                    10,
                )
            if hp_cnt:
                pri = os.getenv("HIGH_PRIORITIES", "Highest,High")
                pri_list = ",".join([f'"{p.strip()}"' for p in pri.split(",") if p.strip()])
                hp_keys = search_issue_keys(
                    JIRA_DOMAIN,
                    auth,
                    f"Sprint={sid} AND type in subTaskIssueTypes() AND priority in ({pri_list}) AND statusCategory = \"To Do\"",
                    10,
                )
        # Evidence topN
        ev_rows = extras.get("evidence", []) or []
        # Markdown compose
        md = []
        md.append(f"## Ë¶ÅÁ¥Ñ | {ts}")
        md.append(f"What: {sprint_label} ‚Äî {sprint_total} tasks, Done {sprint_done} ({int((sprint_done/max(1,sprint_total))*100)}%). (data: sprint_total={sprint_total}, sprint_done={sprint_done})")
        if (sprint_done / max(1, sprint_total)) < target_done_rate:
            if review_avg is not None:
                md.append(f"So what: ÁõÆÊ®ô{target_pct}%Êú™ÈÅî„ÄÅ„É¨„Éì„É•„ÉºÊªûÁïô (data: time_in_status[Review].avg={review_avg:.1f}d)")
            else:
                md.append(f"So what: ÁõÆÊ®ô{target_pct}%Êú™ÈÅî")
        else:
            md.append("So what: ÁõÆÊ®ôÈÅîÊàê„Éö„Éº„Çπ")
        md.append(f"Next: È´òÂÑ™ÂÖàÂ∫¶Êú™ÂÆå‰∫Ü{hp_cnt}‰ª∂„ÅÆÂç≥ÊôÇÂâ≤ÂΩì„ÄÅ„É¨„Éì„É•„ÉºÊãÖÂΩì„ÅÆÂ¢óÂì°Ê§úË®é")
        md.append("")
        # If AI full summary exists, append as-is under its own section
        _ai_full = extras.get("ai_full_text") if isinstance(extras, dict) else None
        if isinstance(_ai_full, str) and _ai_full.strip():
            md.append("## AIË¶ÅÁ¥Ñ (Gemini)")
            md.append("")
            md.append(_ai_full.strip())
            md.append("")
        md.append("## „É™„Çπ„ÇØ")
        if overdue_cnt:
            md.append(f"- ÊúüÈôêË∂ÖÈÅé: {overdue_cnt}‰ª∂ ({', '.join(overdue_keys)}) ‚Äî ÂÑ™ÂÖàÂâ≤ÂΩìË¶Å")
        if due_soon_cnt:
            md.append(f"- 7Êó•‰ª•ÂÜÖÊúüÈôê: {due_soon_cnt}‰ª∂ ({', '.join(due_soon_keys)})")
        if hp_cnt:
            md.append(f"- È´òÂÑ™ÂÖàÂ∫¶Êú™ÁùÄÊâã: {hp_cnt}‰ª∂ ({', '.join(hp_keys)})")
        if not (overdue_cnt or due_soon_cnt or hp_cnt):
            md.append("- ÁâπÁ≠Ü„Åô„Åπ„Åç„É™„Çπ„ÇØ„Å™„Åó")
        md.append("")
        md.append("## „Ç®„Éì„Éá„É≥„Çπ (Top)")
        for e in ev_rows:
            _k = str(e.get('key') or '')
            _s = str(e.get('summary') or '').strip()
            if _s:
                ks = f"{_k} {_s}"
            else:
                ks = _k
            md.append(f"- {ks} | {e.get('status')} | {e.get('days'):.1f}d | assignee: {e.get('assignee','')} | why: {e.get('why','')} | {e.get('link')}")
        # Short actions
        md.append("")
        md.append("## Áü≠Êúü„Ç¢„ÇØ„Ç∑„Éß„É≥")
        md.append("1) „É¨„Éì„É•„ÉºÊãÖÂΩì„Çí1ÂêçËøΩÂä† ‚Äî ÊúüÂæÖ: ReviewÂπ≥Âùá„Çí2Êó•Áü≠Á∏Æ")
        md.append("2) ÊúüÈôêË∂ÖÈÅé„ÅÆÂÑ™ÂÖàÂâ≤ÂΩì„Å®„Ç®„Çπ„Ç´„É¨„Éº„Ç∑„Éß„É≥")
        with open(str(base_dir / "sprint_overview_report.md"), "w", encoding="utf-8") as f:
            f.write("\n".join(md))
    except Exception:
        pass
    # Write enriched tasks JSON for analysis
    try:
        enriched = {
            "sprint": {
                "name": sprint_name,
                "startDate": sprint_start,
                "endDate": sprint_end,
            },
            "parents": data.get("parents", []),
            "totals": data.get("totals", {}),
        }
        path_tasks = Path(base_dir) / "sprint_overview_tasks.json"
        with open(str(path_tasks), "w", encoding="utf-8") as f:
            json.dump(enriched, f, ensure_ascii=False, indent=2)
        if os.getenv("DASHBOARD_LOG", "1").lower() in ("1", "true", "yes"):
            print(str(path_tasks))
    except Exception as e:
        if os.getenv("DASHBOARD_LOG", "1").lower() in ("1", "true", "yes"):
            print(f"[warn] enriched tasks JSON „ÅÆÊõ∏„ÅçÂá∫„Åó„Å´Â§±Êïó: {e}")
    # Write metrics JSON for Slack integration
    try:
        totals = data.get("totals", {})
        done_cnt = int(totals.get("done", 0))
        total_cnt = int(totals.get("subtasks", 0))
        metrics = {
            "sprint": {
                "name": sprint_name,
                "startDate": sprint_start,
                "endDate": sprint_end,
            },
            "totals": totals,
            "doneRate": (done_cnt / total_cnt) if total_cnt else None,
            "targetDoneRate": target_done_rate,
            "axis": axis_mode,
            "extrasAvailable": {k: (v is not None) for k, v in (extras or {}).items()},
        }
        with open(str(base_dir / "sprint_overview_data.json"), "w", encoding="utf-8") as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)
    except Exception:
        pass
    print(out_path)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
