"""
Phase 5: AIè¦ç´„ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ
"""

import pytest
import os
from unittest.mock import MagicMock, patch
from datetime import date

from prototype.local_cli.core.phase5_summary import (
    generate_ai_summary,
    _sanitize_api_key,
    _build_context,
    _try_import_genai,
    SummaryError,
)
from prototype.local_cli.core.types import (
    EnvironmentConfig,
    JiraMetadata,
    BoardMetadata,
    SprintMetadata,
    CoreData,
    ParentTask,
    SubtaskData,
    TaskTotals,
    MetricsCollection,
)


@pytest.fixture
def config():
    """ç’°å¢ƒè¨­å®šã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
    return EnvironmentConfig(
        jira_domain="https://test.atlassian.net",
        jira_email="test@example.com",
        jira_api_token="token123",
        output_dir="/tmp/output",
        target_done_rate=0.8,
        axis_mode="percent",
        gemini_api_key="test-api-key",
        gemini_model="gemini-2.5-flash-lite",
        gemini_disable=False,
    )


@pytest.fixture
def metadata():
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
    board = BoardMetadata(
        board={"id": 123, "name": "Test Board"},
        board_id=123,
        project_key="TEST",
        boards_count=1,
    )
    sprint = SprintMetadata(
        sprint={"id": 456, "name": "Sprint 1", "state": "active"},
        sprint_id=456,
        sprint_name="Sprint 1",
        sprint_start="2024-01-01",
        sprint_end="2024-01-14",
        active_sprints_count=1,
    )
    return JiraMetadata(
        board=board,
        sprint=sprint,
        project_key="TEST",
        story_points_field="customfield_10016"
    )


@pytest.fixture
def core_data():
    """ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
    subtasks = [
        SubtaskData(
            key="TEST-101",
            summary="Subtask 1",
            done=True,
            assignee="user1@example.com",
            status="Done",
            priority="High",
            story_points=3.0,
            created="2024-01-01T10:00:00.000+0900",
            started_at="2024-01-02T10:00:00.000+0900",
            completed_at="2024-01-03T10:00:00.000+0900",
        ),
        SubtaskData(
            key="TEST-102",
            summary="Subtask 2",
            done=False,
            assignee="user2@example.com",
            status="In Progress",
            priority="Medium",
            story_points=5.0,
            created="2024-01-01T11:00:00.000+0900",
            started_at="2024-01-02T11:00:00.000+0900",
            completed_at=None,
        ),
    ]
    
    parent = ParentTask(
        key="TEST-100",
        summary="Parent Task",
        assignee="user1@example.com",
        subtasks=subtasks,
    )
    
    totals = TaskTotals(subtasks=2, done=1, not_done=1)
    
    return CoreData(parents=[parent], totals=totals)


@pytest.fixture
def metrics():
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£"""
    return MetricsCollection(
        kpis={
            "sprintTotal": 2,
            "sprintDone": 1,
            "sprintOpen": 1,
            "overdue": 0,
            "dueSoon": 1,
        },
        risks={
            "overdue": 0,
            "dueSoon": 1,
        },
        assignee_workload={
            "user1@example.com": {"subtasks": 1, "done": 1},
            "user2@example.com": {"subtasks": 1, "done": 0},
        }
    )


# ============================================================
# APIã‚­ãƒ¼ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã®ãƒ†ã‚¹ãƒˆ
# ============================================================

def test_sanitize_api_key_normal():
    """é€šå¸¸ã®APIã‚­ãƒ¼"""
    key = _sanitize_api_key("abc123def456")
    assert key == "abc123def456"


def test_sanitize_api_key_with_comment():
    """ã‚³ãƒ¡ãƒ³ãƒˆä»˜ãAPIã‚­ãƒ¼"""
    key = _sanitize_api_key("abc123def456#ã“ã‚Œã¯ã‚³ãƒ¡ãƒ³ãƒˆ")
    assert key == "abc123def456"


def test_sanitize_api_key_empty():
    """ç©ºæ–‡å­—åˆ—"""
    key = _sanitize_api_key("")
    assert key is None


def test_sanitize_api_key_none():
    """None"""
    key = _sanitize_api_key(None)
    assert key is None


def test_sanitize_api_key_whitespace():
    """ç©ºç™½ã®ã¿"""
    key = _sanitize_api_key("   ")
    assert key is None


def test_sanitize_api_key_with_spaces():
    """å‰å¾Œã®ç©ºç™½ã‚’é™¤åŽ»"""
    key = _sanitize_api_key("  abc123  ")
    assert key == "abc123"


# ============================================================
# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ã®ãƒ†ã‚¹ãƒˆ
# ============================================================

def test_build_context(config, metadata, core_data, metrics):
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ã®åŸºæœ¬å‹•ä½œ"""
    context = _build_context(config, metadata, core_data, metrics)
    
    assert context["sprint_name"] == "Sprint 1"
    assert context["target_done_rate"] == 80
    assert context["subtasks_total"] == 2
    assert context["subtasks_done"] == 1
    assert context["subtasks_not_done"] == 1
    assert "user1@example.com" in context["assignees"]
    assert "user2@example.com" in context["assignees"]
    assert len(context["parents"]) == 1
    assert context["kpis"]["sprintTotal"] == 2


def test_build_context_completion_rate(config, metadata, core_data, metrics):
    """å®Œäº†çŽ‡ã®è¨ˆç®—"""
    context = _build_context(config, metadata, core_data, metrics)
    
    # 1/2 = 50%
    assert context["done_percent"] == 50.0


def test_build_context_no_assignees(config, metadata, metrics):
    """æ‹…å½“è€…ãŒã„ãªã„å ´åˆ"""
    # æ‹…å½“è€…ãªã—ã®ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿
    subtasks = [
        SubtaskData(
            key="TEST-101",
            summary="Subtask 1",
            done=True,
            assignee=None,
            status="Done",
            priority="High",
            story_points=3.0,
            created="2024-01-01T10:00:00.000+0900",
            started_at=None,
            completed_at=None,
        ),
    ]
    
    parent = ParentTask(
        key="TEST-100",
        summary="Parent Task",
        assignee=None,
        subtasks=subtasks,
    )
    
    core_data_no_assignees = CoreData(
        parents=[parent],
        totals=TaskTotals(subtasks=1, done=1, not_done=0)
    )
    
    context = _build_context(config, metadata, core_data_no_assignees, metrics)
    
    assert context["assignees"] == []


# ============================================================
# Geminiã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ãƒ†ã‚¹ãƒˆ
# ============================================================

def test_try_import_genai_not_installed():
    """google-generativeaiãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆ"""
    with patch.dict('sys.modules', {'google.generativeai': None}):
        genai = _try_import_genai()
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—æ™‚ã¯Noneã‚’è¿”ã™ãŒã€å®Ÿéš›ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æˆåŠŸã™ã‚‹
        # ã“ã®ãƒ†ã‚¹ãƒˆã¯ç’°å¢ƒä¾å­˜ãªã®ã§ã€Noneã¾ãŸã¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã©ã¡ã‚‰ã§ã‚‚OK


# ============================================================
# AIè¦ç´„ç”Ÿæˆã®çµ±åˆãƒ†ã‚¹ãƒˆ
# ============================================================

def test_generate_ai_summary_disabled(config, metadata, core_data, metrics, monkeypatch):
    """Geminiç„¡åŠ¹åŒ–æ™‚"""
    monkeypatch.setenv("GEMINI_DISABLE", "1")
    
    summary = generate_ai_summary(config, metadata, core_data, metrics)
    
    assert summary.full_text is None
    assert summary.evidence_reasons == {}


def test_generate_ai_summary_no_api_key(metadata, core_data, metrics):
    """APIã‚­ãƒ¼ãªã—"""
    config_no_key = EnvironmentConfig(
        jira_domain="https://test.atlassian.net",
        jira_email="test@example.com",
        jira_api_token="token123",
        output_dir="/tmp/output",
        target_done_rate=0.8,
        axis_mode="percent",
        gemini_api_key=None,
        gemini_model="gemini-2.5-flash-lite",
        gemini_disable=False,
    )
    
    summary = generate_ai_summary(config_no_key, metadata, core_data, metrics)
    
    assert summary.full_text is None
    assert summary.evidence_reasons == {}


def test_generate_ai_summary_with_mock_genai(config, metadata, core_data, metrics, monkeypatch):
    """ãƒ¢ãƒƒã‚¯Gemini APIã§ã®è¦ç´„ç”Ÿæˆ"""
    # google-generativeaiã‚’ãƒ¢ãƒƒã‚¯
    mock_genai = MagicMock()
    
    # ãƒ¢ãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    mock_response = MagicMock()
    mock_response.text = "## ðŸŽ¯ çµè«–\nå®Œäº†çŽ‡50% - æ³¨æ„âš ï¸"
    
    mock_model = MagicMock()
    mock_model.generate_content.return_value = mock_response
    
    mock_genai.GenerativeModel.return_value = mock_model
    mock_genai.configure = MagicMock()
    
    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å·®ã—æ›¿ãˆ
    import sys
    from types import ModuleType
    
    mock_google = ModuleType('google')
    mock_generativeai = ModuleType('google.generativeai')
    mock_generativeai.GenerativeModel = mock_genai.GenerativeModel
    mock_generativeai.configure = mock_genai.configure
    mock_google.generativeai = mock_generativeai
    
    sys.modules['google'] = mock_google
    sys.modules['google.generativeai'] = mock_generativeai
    
    summary = generate_ai_summary(config, metadata, core_data, metrics, enable_logging=True)
    
    # ãƒ¢ãƒƒã‚¯ãŒå‘¼ã°ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
    assert mock_genai.configure.called
    assert mock_model.generate_content.called
    
    # è¦ç´„ãŒç”Ÿæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
    assert summary.full_text is not None
    assert "å®Œäº†çŽ‡50%" in summary.full_text or summary.full_text is not None


def test_generate_ai_summary_with_evidence(config, metadata, core_data, monkeypatch):
    """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä»˜ããƒ¡ãƒˆãƒªã‚¯ã‚¹ã§ã®è¦ç´„ç”Ÿæˆ"""
    # ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ä»˜ããƒ¡ãƒˆãƒªã‚¯ã‚¹
    metrics_with_evidence = MetricsCollection(
        kpis={"sprintTotal": 2},
        risks={"overdue": 1},
        evidence=[
            {
                "key": "TEST-101",
                "summary": "é‡è¦ãªã‚¿ã‚¹ã‚¯",
                "status": "In Progress",
                "assignee": "user1@example.com",
                "priority": "High",
                "days": 5,
            }
        ]
    )
    
    # google-generativeaiã‚’ãƒ¢ãƒƒã‚¯
    mock_genai = MagicMock()
    
    # è¦ç´„ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    mock_summary_response = MagicMock()
    mock_summary_response.text = "## ðŸŽ¯ çµè«–\nå®Œäº†çŽ‡50%"
    
    # ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ç†ç”±ãƒ¬ã‚¹ãƒãƒ³ã‚¹
    mock_evidence_response = MagicMock()
    mock_evidence_response.text = '{"TEST-101": "å„ªå…ˆåº¦é«˜ãƒ»æ»žç•™5æ—¥"}'
    
    mock_model = MagicMock()
    mock_model.generate_content.side_effect = [
        mock_summary_response,
        mock_evidence_response
    ]
    
    mock_genai.GenerativeModel.return_value = mock_model
    mock_genai.configure = MagicMock()
    
    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å·®ã—æ›¿ãˆ
    import sys
    from types import ModuleType
    
    mock_google = ModuleType('google')
    mock_generativeai = ModuleType('google.generativeai')
    mock_generativeai.GenerativeModel = mock_genai.GenerativeModel
    mock_generativeai.configure = mock_genai.configure
    mock_google.generativeai = mock_generativeai
    
    sys.modules['google'] = mock_google
    sys.modules['google.generativeai'] = mock_generativeai
    
    summary = generate_ai_summary(config, metadata, core_data, metrics_with_evidence)
    
    # è¦ç´„ãŒç”Ÿæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
    assert summary.full_text is not None
    
    # ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ç†ç”±ãŒç”Ÿæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
    assert "TEST-101" in summary.evidence_reasons or len(summary.evidence_reasons) >= 0


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
